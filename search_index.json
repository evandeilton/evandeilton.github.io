[
["index.html", "R NA PRÁTICA: Estatística Descomplicada com R Introdução Motivação Pré-requisitos Ambiente de trabalho", " R NA PRÁTICA: Estatística Descomplicada com R José Evandeilton Lopes 03/06/2019 Introdução Bem vindo ao primeiro módulo de Estatística descomplicada com o R que é uma produção exclusiva para do projeto R NA PRÁTICA. Esta série será composta por quatro módulos e neste primeiro, abordaremos os principais conceitos estatísticos e análise descritiva. O objetivo maior desta parte é revisar os conceitos mais importantes do inicio dos estudos estatísticos. Abordaremos a parte conceitual com algumas definições e termos estatísticos, veremos tabelas de frequências, bem como as principais medidas descritivas (média, mediana e outras). Veremos ainda algumas medidas de correlação e associação e os principais gráficos estatísticos mais utilizados. Para reforçar os conhecimentos, faremos exercícios práticos com apoio do R com foco em bases de dados reais do INEP - Instituto Nacional de Estudos e Pesquisas Educacionais Anísio Teixeira do ano de 2017. No final deste módulo você será capaz de: Definir estatística; Compreender os principais tipos de variáveis e entender as melhores técnicas paracada tipo de variável; Entender o que é e como utilizar tabelas de frequências simples e de dupla entrada; Trabalhar com as principais medidas estatísticas (media, mediana, desvio padrão, etc.); Entender correlação, covariância, estatística Qui-quadrado e V de Crámer; Construir gráficos estatísticos para os tipos corretos de dados com o pacote ggplot2. Motivação A estatística é matemática aplicada e está em tudo! É atribuída a H.G. Wells a seguinte frase: “Statistical thinking will one day be as necessary for efficient citizenship as the ability to read and write. — H.G. Wells” Que em português se traduz em algo como: “O conhecimento estatístico um dia será tão necessário para uma cidadania eficiente quanto a habilidade de ler e escrever.” Nesta frase podemos trocar termo “um dia será …” para “hoje é…”, pois nos dias atuais nossas vidas são afetadas significaivamente pelo conhecimento estatístico de tal forma que não podemos ignorar este fato. Veja alguns exemplos de onde a estatística pode ser aplicada: Na sua lista de compras: Sim, é importante medir as diferenças de preços dos produtos e o percentual de seu salário gasto com alimentos pra não ficar sem grana por aluguel; Na previsão do tempo: Sair sem guarda-chuva ou de bicicleta em um dia de chuva, nem pensar. Mas você não saberia o que fazer pela manhã se observasse o dia claro e sem sinais de chuva. Somente uma previsão estatística confiável seria capaz de te ajudar a decidir antecipadamente; Na pesquisa científica: Toda pesquisa científica usa estatística. Se não utilizar é porque não é científica mas sim especulativa; Em seguros: Seguros de vida, de veículos, de saúde, dental, daquele bumbum siliconado. Tudo envolve estatística. É através dela que os estatísticos constroem os melhores modelos com base em variáveis históricas e nas segmentações de perfis de cada grupo de indivíduos; Em pesquisas médicas: Controle de epidemias, vacinas, taxas de sobrevida, taxas de recuperação de tecidos e ossos, regressão de doenças infecciosas, testes de grupos de risco e uma infinidade de situações utilizam estatística para prever, aumentar e melhorar processos que trazem ganho para a saúde e vida das pessoas; Em testes de qualidade: A estatística bate forte na hora de uma empresa obter uma certificação ISO. Seja no controle estatístico de processos, gráficos de controle e/ou gestão da qualidade, sem esta ciência estes nichos não teriam os mesmos resultados; No monitoramento de ataques de vírus: A empresa Kaspesrki por exemplo, coleta dados globais de vírus e sintetiza em um mapa do globo virtual denominado cybermap. Através dele o usuário pode navegar e obter estatísticas relevantes sobre atividades de vírus nos países pelo mundo. No IDH e expectativa de vida: O IDH (Índice de Desenvolvimento Humano) de um país é um bom indicador de desenvolvimento do mesmo. Não tem como calcular IDH sem modelos estatísticos e matemáticos. Pré-requisitos Para fazer o melhor proveito deste material, temos as seguintes recomendações: Tenha um computador com acesso á internet, R e Rstudio instalados para poder fazer pesquisa, download e resolver/replicar os exercícios propostos e resolvidos; Dedique pelo menos 2 horas da sua semana para ler o material e resolver os exercícios propostos praticando sempre com o R; Sempre que alguma dúvida surgir e não conseguir resolver com ajuda do material, contatar o professor via plataforma para obter suporte adicional ou buscar na Internet; Algum conhecimento prévio da linguagem R ou lógica de programação. Este item não é brigatório, mas quem tiver pdoerá melho usufruir deste material; Uma base mínima de cálculo é recomendada para melhor compreensão de algumas expressões matemáticas abordadas. Ambiente de trabalho Este curso não tem a intenção de ensinar detalhadamente programação em R, pois o foco é em estatística. Contudo, sempre que necessário explicaremos algumas funções e comandos utilizados nos scripts. Além disso, para todos os exemplos e exercícios, deixaremos os códigos gerados como forma de estudo e revisão para que tudo possa ser replicado e reaproveitado pelo aluno. Se sentir dificuldade em compreender algum conceito em linguagem R, recomendamos fazer o nosso curso R NA PRÁTICA: Data Wrangling com R para Ciência de Dados ou qualquer outro do seu interesse para obter mais conhecimentos dobre a linguagem R. Pacotes Trabalharemos com o software R e com a IDE (Ambiente de Desenvolvimento Integrado, traduzindo do inglês) RStudio Desktop. Nos links você poderá baixar os dois programas e configurar de acordo com o seu sistema operacional. Trabalharemos sempre que possível com o operador %&gt;% (pipe) e com funções dos pacotes do tidyverse e outros relacionados. Especialmente para o R NA PRÁTICA, desenvolvemos o pacote rnp que poderá ser baixado direto to github. Este pacote está em constante atualização e possui recursos extras para deste livro e também de outros materiais do R NA PRÁTICA em desenvolvimento. Rode o comando abaixo para instalar, caso ainda não tenha o pacote. # Istalar devtools, caso não exista na máquina. if(!require(&quot;devtools&quot;)) { install.packages(&quot;devtools&quot;, dependencies = TRUE) } # Istalar o rnp require(devtools, quietly = TRUE) if(!require(&quot;rnp&quot;)) { devtools::install_github(&quot;evandeilton/rnp&quot;) } Caso sua instalação do R seja nova, ao instalar o rnp, automaticamente todas as dependências serão baixadas e seu R estará equipado com todos os recursos necessários para trabalar com este livro. A cada novo módulo adicionaremos novas dependências caso surjam. Conjuntos de dados Trabalharemos com conjuntos de dados do Censo do Ensino Superior no Brasil feito anualmente pelo INEP (Instituto Nacional de Estudos e Pesquisas Educacionais Anísio Teixeira), especificamente para o ano de 2017. Os dados podem ser baixados diretamente na seção de microdados do site neste link Censo da Educação Superior de 2017, ou se preferir, baixar diretamente com o comando abaixo. Em seguinda descompactar os dados utilizando seu descompactador favorito. # Informe o ano dos dados e o local completo de onde deseja salvar os dados # conforme exemplos abaixo. Recomendamos criar uma pasta para salvar os # dados e torná-los mais acessíveis nas aulas. rnp::rnp_get_inep_censo(ano = 2017, salvar = &quot;Dados/INEP/&quot;) # Classes para base de dados das IES dicionario &lt;- &quot;Dados/INEP/ANEXOS/ANEXO I - Dicionario de Dados e Tabelas Auxiliares/Dicionario_de_Dados.xlsx&quot; classes &lt;- rnp::rnp_get_classes_inep(caminho = dicionario, aba = &quot;DM_IES&quot;, retorna_lista = FALSE) # Leitura da base de dados base &lt;- rnp::rnp_read(base = paste0(&quot;Dados/INEP/DADOS/DM_IES.CSV&quot;), sep = &quot;|&quot;, dec = &quot;.&quot;, header = TRUE, encoding = &quot;Latin-1&quot;, verbose = FALSE, showProgress = FALSE) # Aplicando classes aos dados base_ies &lt;- rnp::rnp_aplica_classes(base = base, classes = classes) %&gt;% dplyr::mutate(Sigla = SG_IES, TotalTecnicos = QT_TEC_TOTAL, ReceitaPropria = VL_RECEITA_PROPRIA, DespesaPesquisa = VL_DESPESA_PESQUISA) Note que o argumento salvar na função rnp_get_inep_censo() dever conter o caminho para a pasta onde os dados baixados serão salvos. Se não for passada uma pasta ou seja, salvar = NULL o R baixará os dados na pasta da seção onde o R foi carregagado. Para saber qual é este local digite getwd() no console do R. Você poderá também ler os dados sem decompactar com o pacote readr, mas recomendamos descompartar para leitura mais rápida com a função rnp_read(). base_curso &lt;- readr::read_delim(&quot;Dados/INEP/DADOS/DM_CURSO.zip&quot;, delim = &quot;|&quot;, locale = locale(encoding = &quot;Latin1&quot;)) Também disponibiliamos no pacote rnp os dados dm_curso, dm_docente, dm_ies e dm_local. Para acessar, basta carregar o pacote e utilizar os dados conforme exemplo abaixo. Especificamete para os exemplo deste livro, os dados foram tratados com as descrições das devidas classes e também removemos algumas variáveis com muitos valores nulos. Mantemos apenas as mais importates. Acreditamos que para fins de apŕendizado, estes dados são suficientes. Prém, para ter os ados originais, sugerimos seguir as dicas anteriores. # Carega pacote require(rnp, quietly = TRUE) # Ajuda do conjunto de dados ?rnp::dm_curso ?rnp::dm_docente ?rnp::dm_ies ?rnp::dm_local base_curso &lt;- rnp::dm_curso "],
["estatistica.html", "Capítulo - 1 Estatística 1.1 O que é estatística? 1.2 Fases do trabalho estatístico 1.3 Como utilizar estatística? 1.4 Como não utilizar estatística? 1.5 Estatística, Data Science e Big Data. 1.6 Conceitos e definições", " Capítulo - 1 Estatística A Estatística é um ciência vasta e para tentar entender melhor do que ela trata, vamos conferir algumas definições formais e outras não tão formais. 1.1 O que é estatística? Segundo o dicionário Aurélio, a estatística é: “Ramo das matemáticas aplicadas cujos princípios decorrem da teoria das probabilidades e que tem por objeto o estudo, bem como o agrupamento metódico, de séries de fatos ou de dados numéricos. — Dicionário Aurélio” Figura 1.1: Tenho uma dúvida Calma meu jovem. De fato esta definição é muito complicada. Vamos ver outras definições então! O dicionário do Google também define como: Ramo da matemática que trata da coleta, da análise, da interpretação e da apresentação de massas de dados numéricos. — Google A definição do Google está incompleta, pois não considera dados em formato de texto, apenas numéricos. Temos mais algumas frases a seguir! A estatística é a arte de nunca ter que dizer que você está errado. — C. J. Bradfield Aqui temos uma brincadeira do meio estatístico que expressa flexibilidade. É possível, porém não recomendado contar meias verdades com estatística. Temos ainda a minha favorita! Estatística é a arte de torturar os números até que eles confessem. — Desconhecido Esta brincadeira aparentemente inocente guarda um fato interessante: se explorarmos e estressarmos os dados ao extremo, sempre teremos alguma resposta. Nem sempre é o que queremos saber ou concluir, mas com certeza tiraremos alguma informação dos mesmos utilizando técnicas estatísticas adequadas. Figura 1.2: Não tenho mais dúvidas Diante das definições acima, uma boa adaptação em português mais simples seria: A Estatística é a ciência baseada em probablidade que fornece métodos para a coleta, organização, descrição , apresentação, análise e interpretação de dados para suportar a tomada de decisão. — Adaptação Com base nas definições citadas, fica claro que a estatística serve como uma ciência de apoio à tomada de decisão através de dados. Um jargão que vem sendo utilizado cada vez mais em Analytics, especialmente no marketing é data-driven. Uma empresa que diz possuir uma data-driven culture deverá ter sua cultura a tomada e decisão com base nos dados. Para isso ocorrer de forma excelente, a estatística estará em todas as frentes garantindo precisão, qualidade e confiabilidade nos números que apoiarão a tomada de decisão. Isso faz com que esta ciência seja de total relevância para todos que querem descobrir e entender o que seus dados estão tentando esconder para que seus negócios funcionem de forma otimizada. O processo de coleta, organização, descrição dos dados, cálculo e interpretação de estatísticas pertencem à Estatística descritiva, enquanto a análise e a interpretação dos dados, associado a uma margem de incerteza, geralmente associada a uma amostra ficam por conta da Estatística inferencial ou indutiva fortemente fundamentada na teoria das probabilidades que veremos em módulo específico. 1.2 Fases do trabalho estatístico No contexto das empresas, em geral o planejamento estatístico não existe ou não é feito de forma consistente e isso ocorre muitas vezes devido ao fato de as companhias geram dados de acordo com seus próprios produtos e processos e muitas vezes sem se dar conta de que os dados poderão gerar valor. Em muitos casos, o acúmulo desordenado de dados dificulta a obtenção de conhecimento e consequente tomada de decisão. Empresas competitivas entendem o valor dos dados e investem esforço, tempo e dinheiro para gerar bases de dados robustas e orientadas para o trabalho de Data Science. Por isso, sempre que possível devemos nos esforçar para inserir o trabalho estatístico no planejamento de processos seguindo recomendações científicas, pois isso garantirá que as melhores ferramentas e técnicas serão empregadas desde o início da geração dos dados e maximizará o valor esperado. Como planejar pesquisas estatísticas e experimentos são temas profundos e que não cobriremos neste texto, mas para os leitores interessados sugerimos os textos de (Gil 2008) para Métodos e Técnicas de Pesquisa; Fundamentos de metodologia científica do (Köche 2016). Para planejamento de experimentos, sugerimos o texto de (Montgomery 2017). A figura 1.3 exibe um roadmap das principais etapas do processo estatístico. Figura 1.3: Fases do trabalho estatístico Definição do problema: Este processo inicia sempre pela Definição do problema. Nesta fase inicial é preciso delimitar muito bem o problema de pesquisa. Seja ele simples ou complexo, se esta etapa for mal pensada, poderá conduzir a resultados inesperados ou questões não respondidas; Planejamento: Nesta etapa é preciso responder muitos porquês, afinal não podem restar dúvidas que comprometam futuramente os trabalhos. Deve-se responder questões sobre quais dados utilizar, tamanho e tipo das amostras, custos do projeto, tempo de execução, ferramentas, pessoal qualificado e uma série de questões relacionadas ao projeto. Coleta dos dados: Na etapa de coleta, o pesquisador deve estar atento ás fontes de dados e à qualidade dos mesmos. Seja através de questionários ou de bases já montadas, os dados precisam ser confiáveis e consistentes. Os dados devem ser catalogados respeitando-se o tipo de coleta, se periódica, se contínua, se os dados são primários (gerados pela própria empresa ou pesquisador) ou secundários (gerados por terceiros). Apuração: Esta etapa serve para qualificar os dados e nela são feitas contagens, tabulações, agrupamentos e inserção em bancos de dados para o trabalho de análise. Análise e interpretação: Nesta fase todo o ferramental estatístico entra em ação para analisar e descobrir as relações entre as variáveis buscando responder às hipóteses do problema de pesquisa. A geração de relatórios, apresentações e painéis (dashboards) fazem parte desta etapa e auxiliarão na tomada de decisão e na geração de conhecimento. A comunicação também é uma parte fundamental no final desta etapa pois, é através dela que o trabalho será melhor divulgado/vendido . 1.3 Como utilizar estatística? Esta é uma pergunta vasta, mas com base em nossa experiência e na comunidade estatística, segue nove boas práticas para direcionar o pesquisador. Estatística deve ser utilizada para ajudar a responder perguntas científicas: É importante inserir estatística desde o planejamento do experimento até a condução das análises e por fim a compilação dos conhecimentos adquiridos com base nos dados gerados pela pesquisa. Pessoas se enganam. Dados não: Isso é verdade, mas tome cuidado, pois sinais sempre vêm com ruído. Por isso é fundamental entender muito bem o problema de pesquisa e conhecer seus dados para saber diferenciar dado bom de ruído. Questione as fontes e as formas que foram apresentadas. Planejamento com foco no presente e no futuro: Este é um dos princípios mais violados nas ciências. Muitos só olham o aqui e agora e perdem muito tempo e dinheiro. portanto fique alerta. Fazer as perguntas certas e obter as respostas adequadas pode evitar perda de tempo, dinheiro e dores de cabeça na hora de analisar os dados obtidos de experimento mal planejados. Saiba a validade e sua pesquisa e dos seus dados e tenha em mente a replicabilidade. Se outros poderem chagar aos mesmos resultados será possível conferir robustez aos seus achados. Atenção à qualidade dos dados: Se você tiver acesso ao processo de planejamento e coleta de dados seja cuidadoso e tenha em mente os impactos futuros na condução das análises. Dado ruim pode arruinar um estudo ou conduzir a resultados impróprios. Figura 1.4: Anotei tudo Estatística não é só técnica: Análise estatística é mais que um software. O software estatístico fornece ferramentas para auxiliar as análises, não para definí-las. O contexto científico é crítico, e a chave para a análise estatística baseada em princípios é aproximar os métodos analíticos das questões científicas e de negócio. Busque a simplicidade: As pessoas não gostam de complexidade. Uma boa parte dos modelos estatísticos exige formulação simples. Em muitos casos, uma simples análise descritiva resolve o problema. Tenha em mente que um grande número de medições, dados ausentes, erros, vieses de amostragem e outros fatores podem aumentar a complexidade do modelo e tornar o estudo impraticável. Calcule a variabilidade: faz parte da análise estatística justamente ajudar a avaliar a incerteza, muitas vezes na forma de um erro padrão ou intervalo de confiança, e um dos grandes sucessos da modelagem estatística e inferência é que ela pode fornecer estimativas de erros padrão dos mesmos dados. Ao apresentar resultados, é essencial fornecer alguma noção de incerteza estatística envolvida em seu estudo. Verifique as suposições das suas técnicas: É importante entender as suposições por trás dos métodos estatísticos e fazer o que for possível para entender e avaliar essas suposições. Não deixe que o software faça o papel do analista, ele apenas deve auxiliá-lo no processamento dos dados e nos cálculos. A validação das técnicas e as interpretações são sempre por conta do analista. Torne seu trabalho reprodutível: Resultados replicáveis são fundamentais para que outros pesquisadores/analistas possam revisitar e reprocessar seus achados. Em muitos contextos, a replicação completa é muito difícil ou impossível, como em experimentos de larga escala, como ensaios clínicos multicêntricos, porém é sempre bom perseguir esta meta. Quando possível, forneça o conjunto de dados, juntamente com uma descrição completa da análise. Com isso deve ser possível reproduzir as tabelas, figuras e inferências estatísticas. Melhore drasticamente a capacidade de reproduzir descobertas sendo muito sistemático sobre as etapas da análise, compartilhando os dados e o código usados para produzir os resultados e seguindo as práticas recomendadas de estatística aceitas. 1.4 Como não utilizar estatística? Aqui listamos também nove pontos de atenção para evitar mal uso da estatística. Não minta com estatística: Alguns pesquisadores podem ser tentados a maquiar algum dados para seu benefício ou de outros. É sempre bom ter em mente que sua reputação e carreira podem estar em jogo ao apresentar falsos resultados. Sugerimos aqui uma leitura extra do livro do Darrell Huff, pois para não mentir é importante saber como se mente com estatística. Resista aos mau intencionados: Se alguém te pediu pra fazer algo estatisticamente ilegal ou aplicar uma técnica inadequada, seja resistente e questione. Nem sempre o problema é simples, então é sempre bom ter uma compreensão da situação como um todo. Aprenda a dizer não para evitar problemas futuros. Figura 1.5: Use a média Cuidado com as suposições: É melhor assumir que não tem a resposta no momento e que a traz em outro momento do que inventar suposições incorretas só pra não sair por baixo em uma conversa. Ou pior, realizar um estudo/projeto apoiado por suposições incorretas sobre uma técnica estatística. Cedo ou tarde e você poderá se por em uma saia justa e ter de voltar atrás. Evite ambiguidades: A comunicação estatística precisa ser clara. Em termos estatísticos não há espaço para meias verdades, pois são os dados falando. Tenha certeza do que está falando: Não subestime seu público. É verdade que algumas pessoas não falam ou entendem bem o estatiquês, mas fique alerta, pois muitos são conhecedores desta ciência, então por vias das dúvidas é melhor saber o que você vai comunicar para evitar constrangimentos. Não seja complexo demais nas suas análises e comunicações: Neste ponto seja ponderado, pois nem tudo que é simples é fácil e nem tudo que é difícil é complexo. Do planejamento à entrega é sempre bom ter seu trabalho revisado / acompanhado por outra pessoa de forma a identificar pontos de melhoria. A linguagem, sempre que possível deve ser de simples compreensão. Maria vai com as outras: Muito cuidado. Não é porque todo mundo faz algo de um jeito que você pode assumir que é certo. Censo crítico faz toda a diferença na identificação deste tipo de fenômeno. Cuidado como modelos automáticos: Modelos automatizados ou semi-automatizados podem às vezes gerar saídas inesperadas. “.. todos os modelos são errados, mas alguns são úteis. — George E. P. Box”. Com a popularização do machine learning muitas pessoas tendem a pensar que se colocar os dados no computador e passar o algoritmo tudo ficará pronto. Temos casos recentes de que isso é possível. Não vamos entrar no mérito, mas como já comentamos antes, a inteligência é do analista e saídas imprevistas podem ocorrer. Não acredite apenas na estatística: A estatística é fundamental e sem ela nada podemos fazer com os dados, mas esteja sempre atento ao negócio ou qualquer evento externo que possa influenciar e alterar seus resultados. 1.5 Estatística, Data Science e Big Data. Desde que o conceito de dado passou a existir, a estatística se faz presente. A seguir um pequeno texto que relaciona a estatística com Data Science e Big Data. Estatística e Data Science (Ciência de Dados) são partes inseparáveis. De certa forma, a estatística é um subconjunto da ciência de dados. Mas o que é Data Science? É difícil definir um conceito tão amplo porém, a Wikipedia Norte Americana coloca da seguinte forma: Data science, also known as data-driven science, is an interdisciplinary field about scientific methods, processes and systems to extract knowledge or insights from data in various forms, either structured or unstructured, similar to Knowledge Discovery in Databases (KDD). Fonte: https://www.wikiwand.com/en/Data_science, acesso em “03/06/2019” No texto acima podemos isolar o termo interdisciplinary que remete a um conjunto de muitas áreas do conhecimento. Podemos marcar desta definição aos conceitos: Métodos Científicos - Métodos estatísticos e computacionais, por exemplo; Processos - Organização de passos para atingir um objetivo; Sistemas - Sistemas informatizados, por exemplo, são ferramentas superpoderosas para realizar Data Science. Tudo com objetivo de obter conhecimento com base em dados, sejam eles estruturados ou não estruturados. Expandindo mais um pouco, pode-se incluir o termo Big Data que envolve dados estruturados ou não estruturados em grandes volumes. O conceito de Big Data também é complexo e discutível. (De Mauro, Greco, and Grimaldi 2016) propõem uma definição deste termo como segue. Big Data is the Information asset characterized by such a High Volume, Velocity and Variety to require specific Technology and Analytical Methods for its transformation into Value. Deixamos ao leitor interessado consultar (De Mauro, Greco, and Grimaldi 2016) para mais definições sobre Big Data. Podemos isolar nesta definição os termos: Volume Alto - O termos alto pode ser relativo e depende do tipo de computador que está suportando a análise. Nós entendemos como volume alto qualquer base de dados que não pode ser processada por um sistema de tabulação como LibreOffice calc e seu concorrente da Microsoft; Velocidade - Grandes bases exigem processamento rápido e algorítimos rápidos muitas vezes são mais relevantes que um bom Hardware; Variedade - Bancos de dados de fontes diversas podem ser relacionados para obter conhecimento. Estes termos chave estão direcionados diretamente com tecnologia e métodos estatísticos para transformar dados o obter valor ou seja, conhecimento. Aqui percebemos que Data Science, Big Data possuem muito em comum. Ambas utilizam dados como combustível visando descobrir novos conhecimentos. Ou seja, tudo isso precisa de estatística para fazer sentido. Com base nos conceitos até aqui, poderíamos sugerir nossa própria definição de Data Science. “Data Science é uma ciência ampla que une métodos científicos como a estatística, processos e sistemas tecnológicos buscando, através da análise de dados, sejam eles simples ou Big Data estruturados ou não, obter conhecimento acerca de fenômenos e processos variados”. 1.6 Conceitos e definições A partir de agora iniciamos os estudos de estatística e para melhor compreender alguns conceitos, vamos trabalhar com o conjunto de dados da IES do Censo da Educação Superior no Brasil de 2017. # Carregando pacote rnp require(rnp, quietly = TRUE) # Dados IES base_ies &lt;- rnp::dm_ies # Tabela base_ies %&gt;% dplyr::mutate(Sigla = SG_IES, TotalTecnicos = QT_TEC_TOTAL, ReceitaPropria = VL_RECEITA_PROPRIA, DespesaPesquisa = VL_DESPESA_PESQUISA) %&gt;% dplyr::select(Sigla, TotalTecnicos, ReceitaPropria,DespesaPesquisa) %&gt;% head(n = 10) %&gt;% knitr::kable(digits = 2, align = &quot;llrrr&quot;, booktabs = TRUE, format = tb_formata, caption = &quot;Dez primeiras observações base de IES&quot;) %&gt;% kableExtra::kable_styling(latex_options = &quot;hold_position&quot;) Tabela 1.1: Dez primeiras observações base de IES Sigla TotalTecnicos ReceitaPropria DespesaPesquisa UFMT 1574 6913132 5807924 UNB 3206 63239902 5772538 UFS 1429 3161937 3033336 UFAM 1721 4136205 1490991 UFOP 786 3458763 748715 PUCPR 1275 616991005 11948066 UNICAP 441 142785305 560400 UCS 986 338035351 3380182 UNISINOS 1062 487902230 6687713 UCPEL 246 100089191 3540465 Iniciamos aqui a revisão de alguns dos conceitos utilizados na linguagem estatística de forma simplificada. Isso nos ajudará a falar os termos e alguns jargões da linguagem estatística para enriquecer o diálogo. 1.6.1 População, amostra, censo População: É o conjunto de todos os elementos (pessoas, animais, plantas, etc.) que possuam alguma característica de interesse. Amostra: É um pedaço ou subconjunto da população e, a partir dela, faz-se inferência sobre as características da população. A ideia de amostra significativa vem do fato de que para representar a população, a amostra precisa preservar suas características. Figura 1.6: População e amostra Censo: É o processo utilizado para coletar dados abordando todos os elementos de uma população. Neste caso não há necessidade de amostras, pois toda a população é considerada. Parâmetro: É qualquer medida numérica que serve para descrever uma característica de uma população. São geralmente representados por letras gregas. Por exemplo: média (\\(\\mu\\)), variância (\\(\\sigma^2\\)) e desvio padrão (\\(\\sigma\\)). Estatística: Tem a mesma função do parâmetro, porém é medido na amostra. São geralmente representados por letras latinas com acentos. Por exemplo: média amostral (\\(\\bar X\\)), variância (\\(S^2\\)) e desvio padrão (\\(S\\)) amostrais. 1.6.2 Dados, informação, conhecimento e sabedoria Dados: Dados são resultados de medições ou qualquer fonte relato documentado. Por si só dados não tem significado concreto porém, a disponibilidade dos mesmos é matéria prima para a obtenção de informações. Dados podem ser obtidos pela percepção através dos sentidos, pela execução de um processo de medição, por sensores, pesquisas, censos, etc. Informação: O processamento e análise dos dados gera informação que auxilia a tomada de decisão seja nos negócios, pela ciência e na vida cotidiana em geral. Conhecimento: O conhecimento extrapola a informação, ele produz ideias e experiências. Através do conhecimento é possível a abstração e a evolução de ideias e conceitos novos com base em todo tipo de experiência, sejam elas oriundas das informações ou vivências. Sabedoria: Vai além do conhecimento e trata-se de um conhecimento extenso e profundo de várias coisas e suas relações com múltiplos eventos ou de um tópico em particular explorado ao extremo. Geralmente a sabedoria vem guiada por experiências práticas e vivências. Neste nível o conhecimento é extrapolado e visto de vários ângulos. 1.6.3 Variáveis Variáveis são características medidas em cada elemento da amostra ou população. Elas podem ter valores numéricos ou não numéricos e seus valores podem varia de elemento para elemento. Figura 1.7: Tipos de variáveis A figura 1.7 traz um resumo dos tipos mais comuns de variáveis. Detalhamos um pouco mais a seguir. Variáveis qualitativas: As variáveis categóricas ou qualitativas descrevem caraterísticas dos indivíduos da amostra ou população. Elas podem ser nominais, quando descrevem características arbitrárias sem efeito de ordenação ou ordinais, quando descrevem relações de ordenação. A coluna Sigla da tabela 1.1 representa uma variável qualitativa nominal. Exemplos de ordinais são classe social e escolaridade. Variáveis quantitativas: As variáveis numéricas ou quantitativas se classificam em discretas e contínuas. As discretas representam contagens e as contínuas, medidas geralmente com casas decimais. Na tabela 1.1, a coluna TotalTecnicos que representa o total de técnicos das IES é um bom exemplo de variável quantitativa discreta. Já as colunas ReceitaPropria e DespesaPesquisa são variáveis contínuas, pois são medidas que representam valores de receita. Séries temporais: As variáveis quantitativas quando indexadas de uma variável de tempo, por exemplo hora, dia, mês, ano, etc. são classificadas como séries temporais. Séries temporais possuem um grande valor e por isso a estatística reserva um campo completo de estudos para este tipo de dado. 1.6.4 Análise univariada, bivariada e multivariada A análise univariada: Busca-se descrever a população ou amostra analisando cada variável de forma isolada. É a maneira mais simples de obter informação e de fazer a estimativa estatística. Exemplos de análises univariadas são as médias, medianas e quatis. A análise bivariada: Analisa relações existentes entre pares de variáveis para fins de explicação e/ou previsão. Na análise bivariada, a formulação de uma hipótese precisar ser feita e a estatística permitirá inferir ou confirmar esta hipótese. Análise de correção entre duas variáveis e tabelas de frequência de dupla entrada são exemplos de análise bivariada A análise multivariada: Na análise multivariada a estatística dispões de uma série de técnicas que analisam de forma conjunta as múltiplas relações das variáveis. Regressão múltipla, análise de cluster e fatorial são exemplos de análises multivariadas. 1.6.5 tidydata Em seu artigo, (Wickham and others 2014) discutem e mostram uma forma repensada de organizar tabelas estruturadas para análise de dados. De forma simples, um significado para tidy data é: dados arrumados, organizados. Um conjunto de dados para ser tidy precisa ter três ingredientes: Cada observação é uma linha; Cada variável é uma coluna; Cada valor está em uma célula (linha x coluna); Dados neste formato ajudam a tornar a análise mais rápida, principalmente com as ferramentas do tidyverso (Wickham 2017). A Tabela 1.1 mostra uma configuração de dados tidy, onde cada linha representa uma observação ou indivíduo que no caso é uma IES; cada coluna representa uma variável ou característica, por exemplo Sigla ou ReceitaPropria da IES e o cruzamento entre linhas e colunas são os valores correspondentes. Observação: Nas empresas o conceito de tidy data geralmente é atribuído ao que chamam de ABT (Analytics Base Table). Este é o estado da arte que nem sempre é fácil de se chagar, mas uma vez lá, os dados estarão prontos para todo tipo de análise estatística e modelagem. # Exemplos de tidydasets knitr::kable( list(head(mtcars[,1:4], 10), head(dplyr::starwars[,1:4], 10)), booktabs = TRUE, format = tb_formata, caption = &quot;Amostra de outras tabelas de dados organizados&quot;) %&gt;% kableExtra::kable_styling(latex_options = &quot;hold_position&quot;) Tabela 1.2: Amostra de outras tabelas de dados organizados mpg cyl disp hp Mazda RX4 21.0 6 160.0 110 Mazda RX4 Wag 21.0 6 160.0 110 Datsun 710 22.8 4 108.0 93 Hornet 4 Drive 21.4 6 258.0 110 Hornet Sportabout 18.7 8 360.0 175 Valiant 18.1 6 225.0 105 Duster 360 14.3 8 360.0 245 Merc 240D 24.4 4 146.7 62 Merc 230 22.8 4 140.8 95 Merc 280 19.2 6 167.6 123 name height mass hair_color Luke Skywalker 172 77 blond C-3PO 167 75 NA R2-D2 96 32 NA Darth Vader 202 136 none Leia Organa 150 49 brown Owen Lars 178 120 brown, grey Beru Whitesun lars 165 75 brown R5-D4 97 32 NA Biggs Darklighter 183 84 black Obi-Wan Kenobi 182 77 auburn, white . 1.6.6 Exercícios resolvidos Com apoio da base de IES, cuja amostra foi mostrada na tabela 1.1 vamos exercitar os conceitos vistos até agora. População e amostra Exercício 1.1 Quem é a população de IES? Solução. Neste caso, a população se confunde com um censo, pois a base das IES faz parte do levantamento censitário de 2017 e contempla, a princípio todas as IES do Brasil paste(nrow(base_ies), &quot;Universidades.&quot;) ## [1] &quot;2448 Universidades.&quot; Exercício 1.2 O que poderia ser uma amostra da base de IES? Solução. Uma amostra poderia ser todas as IES grandes com mais de 2000 técnicos. paste(&quot;A base tem&quot;, base_ies %&gt;% transmute(TotalTecnicos = QT_TEC_TOTAL) %&gt;% filter(TotalTecnicos &gt; 2000) %&gt;% nrow(), &quot;IES com mais de 2000 técnicos&quot;) ## [1] &quot;A base tem 29 IES com mais de 2000 técnicos&quot; Exercício 1.3 Defina um parâmetro desta base. Solução. Neste caso poderíamos definir \\(\\mu_{receita}\\) como a receita própria média das IES brasileiras porque se trata e um censo. Exercício 1.4 Qual seria uma estatística? Solução. A receita média média da amostra de SP pode ser definida uma estatística dada por \\(\\bar X_{receita}\\) Dados, informação e conhecimento Exercício 1.5 A tabela de IES possui muitos registros numéricos e também textuais. Ela representa melhor, dados, informações ou conhecimento? Solução. Valores brutos em uma tabela são exemplos de dados que por sí só não são informação. Assim a tabela representa um conjunto de dados Exercício 1.6 A frase, ‘O estado de São Paulo possui o maior número de IES do Brasil’ é um exemplo de dado, informação ou conhecimento? Solução. Trata-se de informações que podem ser obtidas através de uma contagem de todas as IES do estado de São Paulo Exercício 1.7 “Um estado que possui muitas universidades terá indicadores de educação superiores.” Esta frase é um exemplos de… Solução. Conhecimento abstraído do fato de que muitas universidades em um estado podem representar alto índice de formação de seu povo. Variáveis e tipos de análises Exercício 1.8 No conjunto de IES temos quantas variáveis e quantas observações? Solução. A base IES possui 2448 linhas (observações) e 47 colunas (variáveis). Esta informação poderá ser obtida através da função rnp_atributos(). # Listando os atributos da base de ies para as 10 primeiras colunas rnp::rnp_atributos(base_ies) %&gt;% head(n = 10) %&gt;% knitr::kable(booktabs = TRUE, format = tb_formata) %&gt;% kableExtra::kable_styling(latex_options = &quot;hold_position&quot;) classeBase comprimento variaveis classeVars data.table 2448 linhas e 47 colunas NU_ANO_CENSO integer data.table 2448 linhas e 47 colunas CO_IES integer data.table 2448 linhas e 47 colunas NO_IES character data.table 2448 linhas e 47 colunas SG_IES character data.table 2448 linhas e 47 colunas CO_MANTENEDORA integer data.table 2448 linhas e 47 colunas NO_MANTENEDORA character data.table 2448 linhas e 47 colunas CO_REGIAO integer data.table 2448 linhas e 47 colunas CO_UF integer data.table 2448 linhas e 47 colunas CO_MUNICIPIO integer data.table 2448 linhas e 47 colunas QT_TEC_TOTAL integer Exercício 1.9 A mediana da receita própria anual das IES brasileiras é R$ 7.429.221,00. Que tipo de análise é esta? Solução. Olhando apenas para uma variável, temos uma análise univariada. Exercício 1.10 A correlação entre o total de técnicos e a receita própria é muito baixa (0.0577). Que tipo de análise é esta? Solução. Neste caso relaciona-se duas variáveis, então temos uma análise bivariada. Exercício 1.11 Conjuntamente, as variáveis Receita propria e Depesa com pesquisa não explicam o Total de tecnicos. Que tipo de análise é esta? Solução. Como temos o relacionamento de três variáveis, neste caso temos uma análise multivariada. . Referências "],
["estatistica-descritiva.html", "Capítulo - 2 Estatística descritiva 2.1 Variáveis categóricas 2.2 Variáveis numéricas 2.3 Variáveis categóricas versus numéricas 2.4 Medidas de associação 2.5 Exercícios de estatística descritiva", " Capítulo - 2 Estatística descritiva Técnicas para descrever e sumarizar conjuntos de dados de natureza diversa fazem parte da estatística descritiva. Entre estas técnicas, estão tabelas de frequências, resumos numéricos e gráficos de acordo com o tipo de variável envolvida. Neste capítulo trataremos destas técnicas sempre com foco em conjuntos de dados do Censo de Educação Superior do INEP. 2.1 Variáveis categóricas No ramo esquerdo da figura 1.7 temos as variáveis qualitativas. Elas são em geral, variáveis em formato de texto ou números inteiros que representam atributos nominais ou ordinais de determinada observação ou indivíduo de uma base de dados. A seguir vamos apresentar algumas técnicas descritivas para este tipo de variável e para melhor exemplificar vamos trabalhar com mais algumas variáveis do conjunto de dados dos docentes do ensino superior do censo do INEP de 2017. Para mais informações sobre as variáveis consulte o dicionário de dados da base. As melhores técnicas utilizadas são variáveis categóricas são contagens/frequências, proporções/percentuais e gráficos. # Classes dos dados base_docentes &lt;- rnp::dm_docente # Variáveis importantes da base de Docentes vars_doc &lt;- c(&quot;CO_IES&quot;, &quot;DESC_TP_CATEGORIA_ADMINISTRATIVA&quot;, &quot;DESC_TP_SEXO&quot;, &quot;NU_IDADE&quot;, &quot;DESC_TP_ESCOLARIDADE&quot;,&quot;DESC_TP_REGIME_TRABALHO&quot;, &quot;CO_DOCENTE&quot;,&quot;DESC_TP_SITUACAO&quot;) base_docentes &lt;- base_docentes %&gt;% dplyr::mutate(faixaIdade = if_else(NU_IDADE &lt;= 30, &quot;01.Até 30 anos&quot;, if_else(NU_IDADE &lt;= 40, &quot;02.Entre 30 e 40 anos&quot;, if_else(NU_IDADE &lt;= 50, &quot;03.Entre 40 e 50 anos&quot;, if_else(NU_IDADE &lt;= 60, &quot;04.Entre 50 e 60 anos&quot;, &quot;05.Acima de 60 anos&quot;))))) %&gt;% dplyr::rename(cdDocente = CO_DOCENTE, cdIES = CO_IES, catAdm = DESC_TP_CATEGORIA_ADMINISTRATIVA, situacao = DESC_TP_SITUACAO, escolaridade = DESC_TP_ESCOLARIDADE, faixaIdade = faixaIdade, regimeTrabalho = DESC_TP_REGIME_TRABALHO, sexo = DESC_TP_SEXO, idade = NU_IDADE) %&gt;% dplyr::arrange(faixaIdade) rnp::rnp_atributos(base_docentes) %&gt;% knitr::kable(booktabs = TRUE, format = tb_formata, caption = &quot;Atributos da base dos docentes&quot;) %&gt;% kableExtra::kable_styling(latex_options = &quot;hold_position&quot;) Tabela 2.1: Atributos da base dos docentes classeBase comprimento variaveis classeVars data.frame 392036 linhas e 42 colunas NU_ANO_CENSO integer data.frame 392036 linhas e 42 colunas cdIES integer data.frame 392036 linhas e 42 colunas CO_DOCENTE_IES integer data.frame 392036 linhas e 42 colunas cdDocente numeric data.frame 392036 linhas e 42 colunas NU_ANO_NASCIMENTO integer data.frame 392036 linhas e 42 colunas NU_MES_NASCIMENTO integer data.frame 392036 linhas e 42 colunas NU_DIA_NASCIMENTO integer data.frame 392036 linhas e 42 colunas idade integer data.frame 392036 linhas e 42 colunas CO_PAIS_ORIGEM integer data.frame 392036 linhas e 42 colunas CO_UF_NASCIMENTO integer data.frame 392036 linhas e 42 colunas CO_MUNICIPIO_NASCIMENTO integer data.frame 392036 linhas e 42 colunas DESC_IN_ATUACAO_EAD character data.frame 392036 linhas e 42 colunas DESC_IN_ATUACAO_EXTENSAO character data.frame 392036 linhas e 42 colunas DESC_IN_ATUACAO_GESTAO character data.frame 392036 linhas e 42 colunas DESC_IN_ATUACAO_GRAD_PRESENCIAL character data.frame 392036 linhas e 42 colunas DESC_IN_ATUACAO_PESQUISA character data.frame 392036 linhas e 42 colunas DESC_IN_ATUACAO_POS_EAD character data.frame 392036 linhas e 42 colunas DESC_IN_ATUACAO_POS_PRESENCIAL character data.frame 392036 linhas e 42 colunas DESC_IN_ATUACAO_SEQUENCIAL character data.frame 392036 linhas e 42 colunas DESC_IN_BOLSA_PESQUISA character data.frame 392036 linhas e 42 colunas DESC_IN_DEFICIENCIA_AUDITIVA character data.frame 392036 linhas e 42 colunas DESC_IN_DEFICIENCIA_BAIXA_VISAO character data.frame 392036 linhas e 42 colunas DESC_IN_DEFICIENCIA_CEGUEIRA character data.frame 392036 linhas e 42 colunas DESC_IN_DEFICIENCIA_FISICA character data.frame 392036 linhas e 42 colunas DESC_IN_DEFICIENCIA_INTELECTUAL character data.frame 392036 linhas e 42 colunas DESC_IN_DEFICIENCIA_MULTIPLA character data.frame 392036 linhas e 42 colunas DESC_IN_DEFICIENCIA_SURDEZ character data.frame 392036 linhas e 42 colunas DESC_IN_DEFICIENCIA_SURDOCEGUEIRA character data.frame 392036 linhas e 42 colunas DESC_IN_EXERCICIO_DATA_REFERENCIA character data.frame 392036 linhas e 42 colunas DESC_IN_SUBSTITUTO character data.frame 392036 linhas e 42 colunas DESC_IN_VISITANTE character data.frame 392036 linhas e 42 colunas catAdm character data.frame 392036 linhas e 42 colunas DESC_TP_COR_RACA character data.frame 392036 linhas e 42 colunas DESC_TP_DEFICIENCIA character data.frame 392036 linhas e 42 colunas escolaridade character data.frame 392036 linhas e 42 colunas DESC_TP_NACIONALIDADE character data.frame 392036 linhas e 42 colunas DESC_TP_ORGANIZACAO_ACADEMICA character data.frame 392036 linhas e 42 colunas regimeTrabalho character data.frame 392036 linhas e 42 colunas sexo character data.frame 392036 linhas e 42 colunas situacao character data.frame 392036 linhas e 42 colunas DESC_TP_VISITANTE_IFES_VINCULO character data.frame 392036 linhas e 42 colunas faixaIdade character A tabela 2.1 mostra uma parte dos dados dos decentes contendo algumas variáveis que exploraremos mais adiante. Temos 392036 observações ou docentes de ensino superior no censo de 2017. 2.1.1 Tabelas de frequências As tabelas de frequência são muito úteis para analisar a distribuição dos dados de uma variável segundo suas categorias ou classes, com elas podemos analisar contagens e proporções de cada categoria da variável. Para isso, entra em cena os seguintes conceitos: Classe: É a descrição da categoria ou nível da variável; Frequência absoluta: trata-se da contagem de observações pertencentes a uma dada categoria da variável; Frequência relativa: trata-se da contagem de observações pertencentes a uma dada categoria da variável dividida pelo total de observações. É a representação percentual da frequência absoluta; Frequência absoluta acumulada: é dada pelo soma acumulada das frequências absolutas; Frequência relativa acumulada: é dada pelo soma acumulada das frequências relativas; A junção destas estatísticas constitui uma tabela de frequências que podem ser simples ou de dupla entrada, também chamada de tabela de contingência: 2.1.1.1 Tabela de frequências simples São tabelas simples para apenas uma variável. No pacote rnp inserimos a função rnp_freq() para realizar a tabulação dos dados. rnp::rnp_freq(x = base_docentes$escolaridade, sortd = FALSE, digits = 3) %&gt;% knitr::kable(booktabs = TRUE, format = tb_formata, caption = &quot;Frequências simples escolaridade do docente&quot;) %&gt;% kableExtra::kable_styling(latex_options = &quot;hold_position&quot;) Tabela 2.2: Frequências simples escolaridade do docente classe fa fr Faa Fra 1. Sem graduação 10 0.000 10 0.000 2. Graduação 4613 0.012 4623 0.012 3. Especialização 72301 0.184 76924 0.196 4. Mestrado 154285 0.394 231209 0.590 5. Doutorado 160827 0.410 392036 1.000 A tabela 2.2 exemplifica uma tabela de frequência simples onde podemos analisar diretamente os dados da variável escolaridade dos docentes. Podemos ver que há 392.036 docentes e que destes, 39,4% possuem mestrado e 41,0% doutorado. Juntas, estas duas categorias representam 80,0% da base. Se somarmos os especialistas, temos um total de 98,8%. 2.1.1.2 Tabela de frequências de dupla entrada Quando desejamos analisar a relação entre duas variáveis categóricas, podemos aplicar a mesma ideia da tabela de frequências simples, porém combinando as variáveis de forma cruzada. Sejam \\(X\\) e \\(Y\\) duas variáveis categóricas quaisquer, então podemos construir tabelas cruzadas dos tipos \\(2 \\times 2; 2 \\times l; k \\times 2;k \\times l\\) onde \\(k\\) e \\(l\\) são respetivamente o total de classes da variável \\(X\\) e total de classes da variável \\(Y\\). Caso uma variável possua apenas uma classe \\(1 \\times l; k \\times 1\\)em geral não faz sentido analisar tabela cruzada. Mais adiante falaremos de medidas de associação entre duas variáveis categóricas e para antecipar a leitura deste tipo de dado, apresentamos a tabela 2.1 que ilustra a forma genérica de uma tabela de dupla entrada. Para simplificar a notação, trataremos o caso das frequências absolutas e assumimos que cada cruzamento de \\(X\\) com \\(x_1,x_2,x_3,...,x_k\\) classes por \\(Y\\) com \\(y_1,y_2,y_3,...,y_l\\) classes dado pelo par \\((x_i;y_j)\\) seja representado por \\(n_{ij}\\) com \\(i=1,2,3,...,k\\) e \\(j=1,2,3,...,l\\). Figura 2.1: Tabela de dupla entrada ou contingência Desta notação e disposição dos dados derivamos as seguintes fórmulas estatísticas. \\(n_{ij}\\) : Distribuição de frequência conjunta; \\(n_{i+} = \\sum_{j=1}^ln_{ij}\\) : Total das linhas. Distribuição de frequência marginal de \\(X\\) \\(n_{+j} = \\sum_{i=1}^k n_{ij}\\) : Total das colunas. Distribuição de frequência marginal de \\(Y\\) \\(n = \\sum_{i=1}^k n_{i+} = \\sum_{j=1}^l n_{+j} = \\sum_{i=1}^j \\sum_{i=1}^l n_{ij}\\) : Total geral, soma de todos os valores \\(f_{i|j}^{X|Y} = \\frac{n_{ij}}{n_{+j}}\\) : Distribuição de frequência condicional de \\(X\\) dado que \\(Y=y_j\\) \\(f_{i|j}^{X|Y} = \\frac{n_{ij}}{n_{+j}}\\) : Distribuição de frequência condicional de \\(Y\\) dado que \\(X=x_i\\) \\(f_{ij} = \\frac{n_{ij}}{n}\\) : Distribuição de frequência relativa conjunta de \\(X\\) e \\(Y\\) \\(f_{i+} = \\sum_{j=1}^{l} f_{ij}\\) : Distribuição de frequência relativa marginal de X \\(f_{+j} = \\sum_{i=1}^{k} f_{ij}\\) : Distribuição de frequência relativa marginal de Y \\(f_{i|j}^{X|Y} = \\frac{f_{ij}}{f_{+j}}\\) : Distribuição de frequência relativa condicional de \\(X\\) dado que \\(Y=y_j\\) \\(f_{i|j}^{Y|X} = \\frac{f_{ij}}{f_{i+}}\\) : Distribuição de frequência relativa condicional de \\(Y\\) dado que \\(X=x_i\\) Exercício 2.1 Para resolver os exercicios a seguir, utilize a tabela 2.3 que é tabela de frequências gerada para as variáveis X = escolaridade e Y = sexo do docente. (a) qual o total de doutores? (b) qual a frequência relativa por sexo? (c) qual a frequência relativa por escolaridade? (d) qual a frequência relativa de pessoas do sexo feminino? (e) qual a frequência relativa de pessoas do sexo masculino que são mestres? (f) qual a frequência relativa de doutores que são mulheres? rnp::rnp_2freq(x = base_docentes$escolaridade, y = base_docentes$sexo, digits = 3, percents = FALSE) %&gt;% knitr::kable(booktabs = TRUE, format = tb_formata, caption = &quot;Frequências cruzadas da escolaridade por sexo&quot;) %&gt;% kableExtra::kable_styling(latex_options = &quot;hold_position&quot;) Tabela 2.3: Frequências cruzadas da escolaridade por sexo Tipo Classe X/Y 1. Feminino 2. Masculino Total fa 1. Sem graduação 3 7 10 fa 2. Graduação 1848 2765 4613 fa 3. Especialização 30579 41722 72301 fa 4. Mestrado 73614 80671 154285 fa 5. Doutorado 73812 87015 160827 fa Total 179856 212180 392036 Solução. (a) Na tabela cruzada, doutores ficam na quinta linha, logo fixamos a linha i = 5 e fazemos a soma das colunas de 1 a 2 para sexo. \\(n_{5+} = \\sum_{j=1}^2 n_{ij} = 73812 + 87015 = 160827\\) neste caso temos j=(&quot;1.Feminino&quot;,&quot;02.Masculino&quot;), logo fazemos a soma das linhas fixando cada coluna. \\(n_{+1} = \\sum_{i=1}^5 n_{i1} / n = 179856 / 392036 = 0.4588\\) \\(n_{+2} = \\sum_{i=1}^5 n_{i2} / n = 212180 / 392036 = 0.5412\\) este caso é semelhante ao anterior. Agora temos i = (&quot;1. Sem graduação&quot;,&quot;2. Graduação&quot;,&quot;3. Especialização&quot;,&quot;4. Mestrado&quot;,&quot;5. Doutorado&quot;), varremos as linhas somando as colunas de 1 a 2. \\(n_{1+} = \\sum_{j=1}^2 n_{1j} / n = 10 / 392036 = 0.0000\\) \\(n_{2+} = \\sum_{j=1}^2 n_{2j} / n = 4613 / 392036 = 0.0117\\) \\(n_{3+} = \\sum_{j=1}^2 n_{3j} / n = 72301 / 392036 = 0.1844\\) \\(n_{4+} = \\sum_{j=1}^2 n_{4j} / n = 154285 / 392036 = 0.3935\\) \\(n_{5+} = \\sum_{j=1}^2 n_{5j} / n = 160827 / 392036 = 0.4102\\) este caso é parecido com o caso da letra a), mas agora fixando nas colunas da tabela. j = 1. Feminino, logo precisamos apenas fixar esta coluna e tirar a frequência relativa do total das linhas. \\(n_{+1} = \\sum_{i=1}^5 n_{ij} = 179856 / 392036 = 0.4588\\) agora queremos uma frequência relativa condicional de pessoas do sexo masculino dado que são mestres. Temos que escolaridade é representado pela variável \\(X\\) e sexo pela variável \\(Y\\), assim. \\(f_{i=4|j}^{Y|X=x_4} = \\frac{f_{ij}}{f_{i+}} = \\frac{f_{42}}{f_{41}+f_{42}} = \\frac{80671}{73614 + 80671} = 0.5229\\) qual a frequência relativa de doutores que são mulheres? Neste caso, queremos a frequência relativa condicional de doutores dado que são do sexo feminino. \\(f_{i|j=1}^{X|Y=y_1} = \\frac{f_{ij}}{f_{+j}} = \\frac{f_{51}}{f_{11}+f_{21}+f_{31}+f_{41}+f_{51}}=\\frac{73812}{3+1848+30579+73614+73812}=0.4104\\) Inicialemente parece complicado se localizar na tabela de frequência e estabelecer a notação corretamente. Neste caso, uma dica é varrer visualmente a tabela sempre com a ideia de que i representa representa os indices de cada linha da variável X e j representa os indices de cada coluna da variável Y. 2.1.2 Gráficos para uma variável categórica Além das tabelas de frequência simples também é possível complementar a análise de variáveis categóricas através de gráficos. Os mais conhecidos são os gráficos de setores (ou pizza) e os de barras. Através destes gráficos a informação fica facilmente visível e a obtenção de informações valiosas fica evidente. 2.1.2.1 Setores tb &lt;- rnp::rnp_freq(base_docentes$faixaIdade, sortd = FALSE) p &lt;- ggplot2::ggplot(tb, aes(&quot;&quot;, fr, fill = classe)) p + ggplot2::geom_bar(width = 1, size = 1, color = &quot;white&quot;, stat = &quot;identity&quot;) + ggplot2::coord_polar(&quot;y&quot;) + ggplot2::geom_text(aes(label = paste0(round(100*fr, 1), &quot;%&quot;)), position = position_stack(vjust = 0.5), size=3) + ggplot2::labs(x = NULL, y = NULL, fill = NULL, title = &quot;&quot;) + ggplot2::guides(fill = guide_legend(reverse = TRUE)) + ggplot2::theme_gray() + ggplot2::theme(axis.line = element_blank(), axis.text = element_blank(), axis.ticks = element_blank(), legend.position=&quot;right&quot;, legend.text = element_text(&quot;Classe&quot;)) Figura 2.2: Gráfico de setores para faixa de idade dos docentes Como podemos notar, a figura 2.2 é muito intuitiva para representar visualmente a distribuição de frequências das classes de uma variável categórica. Combinado com as cores de cada fatia, fica claro e objetivo a parcela de cada categoria para explicar o todo que por sua vez representa 100%. 2.1.2.2 Barras Gráficos de barras também são intuitivos e geralmente são preferíveis em relação aos gráficos de setores. Isso ocorre porque o olho humano é mais sensível a linhas do que círculos e formas em 3D e prefere analisar figuras mais limpas. Para expandir seus conhecimentos sobre análise visual, sugerimos a (Tufte and Graves-Morris 2014). p &lt;- ggplot2::ggplot(tb, aes(classe, fr, fill = classe)) p + ggplot2::geom_bar(width = 1, size = 1, color = &quot;white&quot;, stat = &quot;identity&quot;, show.legend = FALSE) + ggplot2::geom_text(aes(label = paste0(round(100*fr, 1), &quot;%&quot;)), position = position_stack(vjust = 1), size=3) + ggplot2::labs(x = NULL, y = NULL, fill = NULL, title = &quot;&quot;) + ggplot2::theme_gray() + coord_flip() + ggplot2::theme(axis.line = element_blank()) Figura 2.3: Gráfico de barras para faixa de idade dos docentes A figura 2.3 mostra um gráfico de barras para as faixas de idade dos docentes, nele pode-se notar que visualmente as diferenças de patemares ficam evidentes. Com isso a leitura fica mais direta e é possível comparar todas as barras simultaneamente. O eixo x contém as proporções e o eixo y a descrição de cada categoria nesta visão horizontal. 2.1.3 Gráfico para duas variáveis categóricas Vimos nas tabelas de frequência que as tabelas de dupla entrada são boas ferramentas para analisar conjuntamente a relação entre duas variáveis, mas isso também pode ser feito de forma visual. 2.1.3.1 mosaicplot Podemos visualizar a relação entre duas variáveis categóricas ou numéricas de poucas classes, através do Gráfico de mosaico (mosaic plot). O pacote ggmosaic expande o ggplot2 para produzir este tipo de gráfico. p &lt;- ggplot2::ggplot(base_docentes) p + ggplot2::theme_gray() + ggmosaic::geom_mosaic(aes(x = product(sexo), fill = faixaIdade), show.legend = FALSE) + ggplot2::labs(x = NULL, y = NULL, fill = NULL, title = &quot;&quot;) + ggplot2::theme(axis.line = element_blank()) Figura 2.4: Gráfico de mosaico para faixa de idade dos docentes por sexo Cada coluna da figura 2.4 representa uma classe da variável sexo do docente e cada linha representa uma classe da variável faixa de idade. Note que o cruzamento entre linhas e colunas geram retângulos com a proporção de cada cruzamento, sendo maior nos casos em que existem mais dados. Por exemplo, proporcionalmente docentes do sexo masculino acima de 60 anos são maioria neste conjunto de dados. 2.1.4 Exercícios Para resolver os exercícios desta seção, utilize o conjunto de dados DM_CURSO.CSV presente na pasta de dados ou no pacote ?rnp::dm_curso. Esta base de dados possui informações sobre os cursos das IES no censo de 2017 do INEP. Mais informações sobre as variáveis podem ser obtidas no dicionario de dados presente na pasta AJUDA/ANEXOS ou no site do INEP. # Dados de cursos base_curso &lt;- rnp::dm_curso dplyr::glimpse(base_curso[,1:10]) ## Observations: 35,693 ## Variables: 10 ## $ NU_ANO_CENSO &lt;int&gt; 2017, 2017, 2017, 20… ## $ CO_IES &lt;int&gt; 789, 4567, 2341, 670… ## $ CO_LOCAL_OFERTA &lt;int&gt; 1033528, 659871, 131… ## $ CO_UF &lt;int&gt; 14, 51, 35, 35, 53, … ## $ CO_MUNICIPIO &lt;int&gt; 1400100, 5107925, 35… ## $ CO_CURSO &lt;int&gt; 1259131, 1258115, 68… ## $ NO_CURSO &lt;chr&gt; &quot;MÚSICA&quot;, &quot;GESTÃO DE… ## $ CO_OCDE_AREA_GERAL &lt;int&gt; 1, 3, 3, 5, 3, 7, 4,… ## $ CO_OCDE_AREA_ESPECIFICA &lt;int&gt; 14, 34, 38, 52, 38, … ## $ CO_OCDE_AREA_DETALHADA &lt;int&gt; 146, 345, 380, 522, … Exercício 2.2 Faça uma análise de frequências da variável DESC_TP_CATEGORIA_ADMINISTRATIVA e responda qual a taxa de cursos por IES tipo pública. Solução. Analisando a tabela de frequências abaixo temos que as três categorias que definem cursos de IES públicas representam 29,7% medidos pela frequência acumulada relativa (Fra). Aqui o resultado refere-se à soma das classes 1, 2 e 3 na ordem em que aparecem. rnp::rnp_freq(base_curso$DESC_TP_CATEGORIA_ADMINISTRATIVA, digits = 3) %&gt;% knitr::kable(booktabs = TRUE, format = tb_formata, caption = &quot;Frequências categoria administrativa&quot;) %&gt;% kableExtra::kable_styling(latex_options = &quot;hold_position&quot;) Tabela 2.4: Frequências categoria administrativa classe fa fr Faa Fra 1. Pública Federal 6538 0.183 6538 0.183 2. Pública Estadual 3558 0.100 10096 0.283 3. Pública Municipal 502 0.014 10598 0.297 4.Privada com fins lucrativos 12488 0.350 23086 0.647 5. Privada sem fins lucrativos 12523 0.351 35609 0.998 7. Especial 84 0.002 35693 1.000 Exercício 2.3 Represente graficamente a variável DESC_TP_CATEGORIA_ADMINISTRATIVA e interprete quais as categorias de maior e menor influência. Solução. Para dados categóricos, os gráficos mais utilizados são de barras e setores. Vamos fazer um gráfico de barras com ggplot2. # Primeiro fazemos as frequências, depois o gráfico tb &lt;- rnp::rnp_freq(base_curso$DESC_TP_CATEGORIA_ADMINISTRATIVA) p &lt;- ggplot2::ggplot(tb, aes(classe, fr, fill = classe)) p + ggplot2::geom_bar(width = 1, size = 0.6, color = &quot;white&quot;, stat = &quot;identity&quot;, show.legend = FALSE) + ggplot2::geom_text(aes(label = paste0(round(100*fr, 1), &quot;%&quot;)), position = position_stack(vjust = 1), size=3) + ggplot2::labs(x = NULL, y = NULL, fill = NULL, title = &quot;&quot;) + ggplot2::theme_gray() + coord_flip() + ggplot2::theme(axis.line = element_blank()) As categorias privada com e privada sem fins lucrativos representam 70,1% dos dados, sendo as mais representativas. Públicas municipais são minoria (1,4%) e especial apenas (0.2%). Temos indicios de que políticas públicas para aumentar a participação de cursos especiais devem ser melhoradas. Exercício 2.4 Olhando para a variável DESC_TP_GRAU_ACADEMICO responda quais as categorias de maior e menor ocorrências de cursos. Desconsidere a categoria missing. Solução. Vamos gerar uma tabela de frequências simples para avaliar as categorias e depois eliminar os dados da categoria missing. # As categorias diferentes de missing são: # 1. Bacharelado, 2. Licenciatura e 3. Tecnológico # missing representam 0.09% dos dados. grau &lt;- c(&quot;1. Bacharelado&quot;, &quot;2. Licenciatura&quot;, &quot;3. Tecnológico&quot;) GrauAcad &lt;- base_curso %&gt;% dplyr::transmute(GrauAcad = DESC_TP_GRAU_ACADEMICO) %&gt;% dplyr::filter(GrauAcad %in% c(&quot;1. Bacharelado&quot;, &quot;2. Licenciatura&quot;, &quot;3. Tecnológico&quot;)) tb &lt;- rnp::rnp_freq(GrauAcad$GrauAcad, digits = 3) p &lt;- ggplot2::ggplot(tb, aes(classe, fr, fill = classe)) p + ggplot2::geom_bar(width = 1, size = 0.6, color = &quot;white&quot;, stat = &quot;identity&quot;, show.legend = FALSE) + ggplot2::geom_text(aes(label = paste0(round(100*fr, 1), &quot;%&quot;)), position = position_stack(vjust = 1), size=3) + ggplot2::labs(x = NULL, y = NULL, fill = NULL, title = &quot;&quot;) + ggplot2::theme_gray() + coord_flip() + ggplot2::theme(axis.line = element_blank()) Como o gráfico mostra, 59,6% dos cursos são de bacharelado frente a 20,6% de licenciatura. Estamos formando poucos professores? Exercício 2.5 Represente a variável DESC_TP_GRAU_ACADEMICO em um gráfico de barras e interprete os resultados para cursos tecnologicos em relação aos cursos de licenciatura. Exercício 2.6 A variável DESC_TP_ORGANIZACAO_ACADEMICA descreve características do tipo de organização, estude esta variável graficamente. Exercício 2.7 Analise conjuntamente as variáveis DESC_IN_POSSUI_LABORATORIO e DESC_TP_CATEGORIA_ADMINISTRATIVA para verificar a existência de laboratórios nos cursos públicos e privados. 2.2 Variáveis numéricas Variáveis numéricas são se longe o tipo mais comum e analisável de dado, pois contemplam medidas de processos diversos. Por exemplo, idade de uma pessoa em dias, peso, altura, total de pessoas em um metrô, em uma fila de cinema e por aí vai. Por permitir cálculos estatísticos, este tipo de variável tem sido estudado há milênios e portanto, boa parte das técnicas estatísticas atuais de baseiam em dados numéricos. Neste tópico abordaremos as principais medidas estatísticas cobrindo centralidade, dispersão entre outras e os principais gráficos que podem ser empregados. 2.2.1 Medidas estatísticas de centraliade Quando olhamos um conjunto de dados de uma variável numérica logo pensamos em alguma forma de resumir estes dados para gerar algum tipo de informação. As medidas estatísticas de centralidade representam resumos numéricos que apontam para o centro do conjunto de dados. A figura 1.7 ilustra a ideia e também indica uma vulnerabilidade da média que são os extremos. Pontos extremos podem inserir viés no valor e na interpretação de uma média, mas para complementar a média temos a mediana, moda e quartis que veremos nos tópicos a seguir. Figura 2.5: Na média, tudo bem As medidas estatísticas descritas nesta seção são aplicadas a conjuntos de dados (amostras e populações) e também a distribuições de probabilidade. Para manter o teor prático deste texto, vamos focar em dados. No capitulo sobre probabilidade retornaremos o assunto no contexto das distribuições de probabilidade. 2.2.1.1 Média (\\(\\bar X, \\mu\\)) Existem muitos tipos de média e entre elas temos a média aritmética, média ponderada, média geométrica e a média harmônica. Em qualquer uma delas, o intuito é resumir a centralidade dos dados em relação a seus extremos dando nenhum, mais ou menos peso para cada observação. Representamos a média aritmética de uma amostra pela letra latina \\(\\bar X\\) (xis-barra) e a média populacional pela letra grega \\(\\mu\\) e calculamos com a mesma expressão matemática. Veremos no capítulo sobre teoria das probabilidades que a média de uma veriável aleatória \\(X\\) é chamada de valor esperado ou esperança de \\(X\\) e geralmente é definido por \\(E[X]\\). Média aritmética: é a soma de todos os valores e dividido pelo total deles. Ou seja, o resultado dessa divisão equivale a um valor médio entre todos os valores e é calculada por: \\[\\bar X = \\frac{x_1 + x_2 + x_3 + \\dots + x_n}{n}, i = 1, 2, 3, \\dots, n\\] onde \\(x_1, x_2, x_3, \\dots, x_n\\) representam cada valor correspondente a um elemento \\(i\\) da amostra e \\(n\\) o total de elementos. Este tipo de média é aplicado preferecialmente quando cada elemento tem peso igual a uma unidade, ou seja, quando não houver muita repetição. Exemplo 2.1 Com base no conjunto de dados de IES, vamos calcular algumas médias. base_ies %&gt;% dplyr::mutate(Sigla = SG_IES, TotalTecnicos = QT_TEC_TOTAL, ReceitaPropria = VL_RECEITA_PROPRIA, DespesaPesquisa = VL_DESPESA_PESQUISA) %&gt;% dplyr::summarise(&quot;Total técnicos&quot; = mean(TotalTecnicos), &quot;Receita própria&quot; = mean(ReceitaPropria), &quot;Depesa pesquisa&quot; = mean(DespesaPesquisa)) %&gt;% knitr::kable(caption = &quot;Média anual para dados de IES&quot;, format = tb_formata) %&gt;% kableExtra::kable_styling(latex_options = &quot;hold_position&quot;) Tabela 2.5: Média anual para dados de IES Total técnicos Receita própria Depesa pesquisa 168.1 145378180 886404 A tabela 2.5 mostra que a média da receita própria anual das IES brasileiras, segundo o censo de 2017, foi de R$ 143.468.742. Este valor parece um pouco suspeito, pois representa 85,76% do PIB (Produto Interno Bruto) do estado de pernambuco tendo 2018 como ano base, segundo dados do IBGE. Mas vamos entender adiante como investigar isso melhor. Média aritmética ponderada: Neste caso, é assumido que cada elemento amostral tem um peso, então a média aritmética ponderada é calculada multiplicando cada valor do conjunto de dados pelo seu peso, somando tudo e dividindo pela soma de todos os pesos. Na verdade a média aritmética simples é um caso especial da ponderada quando cada peso vale 1. A média ponderada é dada por: \\[\\bar X_p = \\frac{p_1 \\times x_1 + p_2 \\times x_2 + p_3\\times x_3 + \\dots + p_n \\times x_n}{p_1 + p_2 + p_3 + \\dots + p_n}, i = 1, 2,3 \\dots, n\\] sendo \\(x_1, x_2, x_3, \\dots , x_n\\) cada valor associado a um \\(i-ésimo\\) elemento da amostra e \\(p_1 + p_2 + p_3 + \\dots + p_n\\) cada peso relacionado com cada elemento da amostra. Quando a amostra possuir muitas repetições ou precisar ser balizada por algum peso, esta média é mais recomendada. Exemplo 2.2 Com base no conjunto de dados de IES, vamos calcular a média da receita própria ponderada pelo total de técnicos. base_ies %&gt;% dplyr::mutate(TotalTecnicos = QT_TEC_TOTAL, ReceitaPropria = VL_RECEITA_PROPRIA) %&gt;% dplyr::summarise(&quot;Receita&quot; = mean(ReceitaPropria), &quot;Receita ponderada&quot; = weighted.mean(x = ReceitaPropria, w = TotalTecnicos)) %&gt;% knitr::kable(format = tb_formata, caption = &quot;Média receita própria ponderada pelo total de técnicos&quot;) %&gt;% kableExtra::kable_styling(latex_options = &quot;hold_position&quot;) Tabela 2.6: Média receita própria ponderada pelo total de técnicos Receita Receita ponderada 145378180 229043797 Note da tabela 2.6, que a média ponderada é maior que a aritmética da tabela 2.5 e isso ocorre porque IES maiores possuem mais receita e sendo esta ponderada por um volume maior de técnicos faz com que a média suba. A média geométrica é mais rara, porém existem aplicações nas ciências sociais como formas de estimar a expectativa de vida ao nascer, na economia como indicadores financeiros e na geometria. Assim como a média geométrica, a harmônica também é rara e possui aplicações na área da física em situações que envolvem taxas. Fica ao cargo do leitor interessado pesquisar mais sobre estes casos especiais de médias. 2.2.1.2 Mediana (\\(M_d\\)) Para compreender melhor o conceito de mediana é importante saber que ela depende da ordenação de forma crescente dos dados da variável numérica. Como se trata de números, ao ordenar os dados podemos trazer a ideia de centro. A mediana é uma medida estatística que calcula o valor central dos dados de forma que se tenha metade dos valores (50%) abaixo e metade acima da mediana. Resumindo, mediana é o valor do meio do conjunto de dados. Quando o conjunto de dados tiver um número impar de observações, a mediana será o valor central e quando o comprimento for par, a mediana será a média dos dois elementos centrais. A mediana também é conhecida como uma medida resistente a pontos discrepantes e como segundo quartil \\(Q_2\\). Exemplo 2.3 No conjunto de dados c(0, 1, 2, 3, 4, 5, 6) qual é a mediana? Neste caso a mediana é 3, porque a amostra tem tamanho 7 (impar) e 3 é o elemento que separa os dados 50% / 50%. No R utilizamos a função median() para calcular a mediana. x &lt;- c(0, 1, 2, 3, 4, 5, 6) median(x, na.rm = TRUE) ## [1] 3 # OBS: na.rm remove elementos nulos da amostra, quando existirem Exemplo 2.4 No conjunto de dados c(2, 3, 4, 5, 6, 7) qual é a mediana? Neste caso a mediana é \\(\\frac{4 + 5}{2} = 4.5\\), porque a amostra tem tamanho 6 (par) sendo que 4 e 5 são os elementos que estão no centro. x &lt;- c(2, 3, 4, 5, 6, 7) median(x, na.rm = TRUE) ## [1] 4.5 2.2.1.3 Moda (\\(M_o\\)) A moda é uma medida estatística que aponta valor(es) mais frequente(s) numa amostra com elementos repetidos, sendo ela o valor ou conjunto de valores mais comuns. Quando os dados são numéricos e já estão agrupados em classes, chamamos a classe com maior frequência de classe modal e seu valor é determinado pela média dos seus extremos. Diferentemente da média e mediana já vistas, a moda também se aplica a variáveis categóricas, uma vez que serve para identificar as classes ou valores mais frequentes. Quando uma amostra possui apenas uma moda diz-se que ele é unimodal, sem tem duas é bimodal e se tem três ou mais é dita multimodal. Exemplo 2.5 Vamos gerar uma tabela de frequências das idades dos docentes e analisar a classe modal. Solução. Neste caso, temos uma variável numérica então utilizamos a função rnp::rnp_freq() para determinar as faixa de idade. Por padrão esta função trabalha com quartis para categorizar dados numéricos. knitr::kable(rnp::rnp_freq(base_docentes$idade), digits = 3, booktabs = TRUE, format = tb_formata, caption = &quot;Frequências para idade dos docentes das IES&quot;) %&gt;% kableExtra::kable_styling(latex_options = &quot;hold_position&quot;) Tabela 2.7: Frequências para idade dos docentes das IES classe fa fr Faa Fra 19–36 107295 0.274 107295 0.274 36–43 95550 0.244 202845 0.517 43–52 92360 0.236 295205 0.753 52–99 96831 0.247 392036 1.000 Na tabela 2.7 vemos que a classe modal é a que contém idades entre 19 e 36 anos, pois ela representa 27,4% da amostra. Com base na classe modal, temos que \\(M_o = \\frac{19+36}{2} = 27,5\\) anos. Exemplo 2.6 Dadas as amostras genéricas x = {2, 5, 3, 4, 4}, y = {5,5,7,7,6,1,2,1}, z = {9,1,7,8,4} determine, quando existir e moda e sua classificação. Solução. Uma forma de verificar se um conjunto de dados possui moda é verificar se tem algum valor que se repete ao longo da amostra. Isso pode ser feito através das funções table() e duplicated(). Enquanto a primeira faz uma tabulação dos valores ou das classes, a segunda varre a variável buscando quem são os valores que ocorrem mais de uma vez e retornando TRUE, caso algum se repita. Vejamos a solução. # Preparando os dados como vetores através da função c() e # ordenando com sort() x &lt;- sort(c(2, 5, 3, 4, 4)) paste(&quot;x possui&quot;, x[duplicated(x)], &quot;como moda&quot;) ## [1] &quot;x possui 4 como moda&quot; # x é unimodal y &lt;- sort(c(5,5,7,7,6,1,2,1)) paste(&quot;y possui&quot;, y[duplicated(y)], &quot;como moda&quot;) ## [1] &quot;y possui 1 como moda&quot; &quot;y possui 5 como moda&quot; ## [3] &quot;y possui 7 como moda&quot; # y é multimodal z &lt;- sort(c(9,1,7,8,4)) paste(&quot;z possui&quot;, z[duplicated(z)], &quot;como moda&quot;) ## [1] &quot;z possui como moda&quot; # z não possui moda. As medidas de centralidade de forma geral sempre buscarão representar quais dados estão no centro ou apontando para mesmo no conjunto de dados. A figura 2.6 exemplifica um conjunto de medidas em uma linha onde a média representa o centro e os pontos as possíveis medidas realizadas. Figura 2.6: Centralidade O centro de massa é onde ocorre a maioria das observações e é nesta região que geralmente a média será encontrada. 2.2.1.4 Exercícios Utilize a base de dados das IES para responder à questão a seguir. Exercício 2.8 Interprete a média e mediana para as seguintes variáveis: QT_TEC_MEDIO_FEM, QT_TEC_MEDIO_MASC, QT_TEC_SUPERIOR_FEM e QT_TEC_SUPERIOR_MASC. Solução. Aplicando as funções mean() e median() com auxílio das funções lapply() do R base e summarise() do pacote dplyr. variaveis &lt;- c(&quot;QT_TEC_MEDIO_FEM&quot;, &quot;QT_TEC_MEDIO_MASC&quot;, &quot;QT_TEC_SUPERIOR_FEM&quot;, &quot;QT_TEC_SUPERIOR_MASC&quot;) tb &lt;- sapply(variaveis, function(i) { base_ies %&gt;% select(i) %&gt;% summarise(&quot;Média&quot; = round(mean(.[[i]], na.rm = TRUE), 2), &quot;Mediana&quot; = round(median(.[[i]], na.rm = TRUE),2)) }) %&gt;%t() knitr::kable(tb, booktabs = TRUE, format = tb_formata, caption = &quot;Média e mediana técnicos (IES)&quot;) %&gt;% kableExtra::kable_styling(latex_options = &quot;hold_position&quot;) Tabela 2.8: Média e mediana técnicos (IES) Média Mediana QT_TEC_MEDIO_FEM 27.26 6 QT_TEC_MEDIO_MASC 27.51 4 QT_TEC_SUPERIOR_FEM 27.87 6 QT_TEC_SUPERIOR_MASC 20.37 3 A tabela mostra que em média, as IES possuem 27 técnicos de nível médio, masculino ou feminino com mediana de 6 para feminino e 4 para masculino. Isso significa que cerca de 50% das IES possuem até 10 (6 + 4) técnicos de nível médio. Para os técnicos de nível superior, a média feminina é superior em quase 8, sendo de 27,87 contra 20,37 dos masculinos. A mediana de mulheres se iguala àquelas com curso técnico. 2.2.2 Medidas estatísticas de dispersão De forma simples, podemos entender medidas de dispersão como estatísticas que medem o quanto os dados estão espalhados. Desta forma, este tipo de medida é zero se os dados são todos iguais e vai aumentando à medida em que a diversidade dos dados aumenta. Estatísticas de dispersão são muito aplicadas em área como física ajudando a medir a variabilidade de medições feitas em experimentos; nas ciências biológicas estimando a variabilidade interindivíduos (membros distintos da mesma amostra são diferentes uns dos outros) e intraindivíduos (um mesmo individuo submetido a algum teste em condições distintas produzem resultados diferentes) e em muitos ramos das ciências como economia, medicina e engenharia. As principais medidas estatísticas de dispersão são desvio padrão (\\(S,\\sigma\\)) e variância (\\(S^2,\\sigma^2\\)), amplitude, desvio absoluto e coeficiente de variação 2.2.2.1 Desvio padrão (\\(S,\\sigma\\)) e variância (\\(S^2,\\sigma^2\\)) Desvio padrão e variância são medidas que buscam estimar a dispersão dos dados em torno da sua média. Quando estamos falando de população temos desvio padrão e variância populacionais. Representados pela letra grega minúscula \\(\\sigma\\) o desvio padrão e \\(\\sigma^2\\) para a variância. No caso de amostra, representamos com a letra latina \\(S\\) o primeiro e \\(S^2\\) para o segundo caso. O desvio padrão populacional é dado por: \\[{\\displaystyle \\sigma ={\\sqrt {{\\frac {1}{N}}\\sum _{i=1}^{N}(X_{i}-\\mu )^{2}}}}\\] em que \\(X_i,i=1,2,...,N\\) são os elementos da população e \\(\\mu\\) é a média populacional. Já o desvio padrão amostral é dado por: \\[{\\displaystyle S_{n-1}={\\sqrt {{\\frac {1}{n-1}}\\sum _{i=1}^{n}(X_{i}-{\\overline {X}})^{2}}}}\\] em que \\(X_i,i=1,2,...,n\\) são os elementos da amostra e \\(\\bar X\\) é a média amostral. Note que o denominador do desvio padrão amostral é \\((n-1)\\) em vez de \\(n\\). Este fator de correção é conhecido como correção de Bessel (Reichmann 1961) e é aplicado porque no cálculo da média a partir da amostra, perde-se um grau de liberdade. Grau de liberdade refere-se ao total de elementos da amostra supondo que cada um é independente do outro. Como \\(S\\) utiliza \\(\\bar X\\) que por sua vez está ligada com cada elemento da amostra, há epenas \\(n-1\\) elementos independentes após \\(\\bar X\\) ser calculado. A variância é o quadrado do desvio padrão. Assim: Variância populacional é dada por \\[\\sigma^2 ={{\\frac {1}{N}}\\sum _{i=1}^{N}(X_{i}-\\mu )^{2}}\\] e a variância amostral por: \\[S_{n-1}={{\\frac {1}{n-1}}\\sum _{i=1}^{n}(X_{i}-{\\overline {X}})^{2}}\\] Em R calculamos o desvio padrão de uma variável com a função sd() e a variância com a função var(). Exemplo 2.7 Calcule a média, desvio padrão e a variância da idade dos docentes das IES. base_docentes %&gt;% dplyr::summarise(`Média` = mean(idade), `Desvio padrão` = sd(idade), `Variância` = var(idade)) ## Média Desvio padrão Variância ## 1 44.53 10.96 120.2 ou diretamente com. paste(&quot;Média =&quot;, round(mean(base_docentes$idade), 3)) ## [1] &quot;Média = 44.531&quot; paste(&quot;Desvio padrão =&quot;, round(sd(base_docentes$idade), 3)) ## [1] &quot;Desvio padrão = 10.963&quot; paste(&quot;Variância =&quot;, round(var(base_docentes$idade), 3)) ## [1] &quot;Variância = 120.181&quot; Interpretação do desvio padrão: No exemplo acima, vemos que a média de idade dos docentes é de 44,53 anos com desvio padrão de 10,96 e variância de 120,20, mas o que isso significa? - A variância de idade é uma medida cuja unidade de media é \\(ano^2\\). Ano ao quadrado não tem interpretação direta então utilizamos o desvio padrão. Em geral quanto maior o desvio padrão mais espalhados estão os dados em relação à media. Não é conhecida uma regra generalizada para dizer se um desvio padrão é menor ou maior, porém, com base na teoria das probabilidades temos uma regra de ouro que é aplicada sempre que a curva dos dados segue uma distribuição Normal (por hora, epenas aceite, veremos ela mais adiante!). Figura 2.7: Centralidade Conforme vemos na figura 2.7, em torno da média mais ou menos um desvio padrão devem estar 68,27% dos dados, já entre a média mais ou menos 2 desvios padrão devem estar 95,45% dos dados. Seguindo esta lógica, a interpretação deve levar em conta a distribuição dos dados e a precisão que o experimento ou estudo exige. Assim, sendo no nosso exemplo a média de idade dos docentes é 44,2 então 68,27% dos docentes devem possuir idades na faixa de \\(44,2 \\pm 11 = (33.4-55.4)\\) anos. 2.2.2.2 Amplitude A amplitude de um conjunto de dados ordenado é a distância entre o menor e o maior valor. Na figura 2.6 se seus valores estiverem ordenados do maior para o menor, a amplitude será o ponto mais à direita Máximo menos o ponto mais à esquerda Mínimo. Representamos um conjunto de dados ordenado da seguinte forma, em que o subscrito representa a ordem da observação. \\[X_{(1)}\\leq X_{(2)}\\leq X_{(3)}\\leq \\cdots \\leq X_{(n-1)}\\leq X_{(n)}\\] Assim, sendo podemos expressar a amplitude ou range por \\[R = X_{(n)} - X_{(1)} = Max(X) - Min(X)\\] Exemplo 2.8 Qual a amplitude da idade dos docentes? # Ordenando os dados do menor para o maior idade &lt;- sort(base_docentes$idade, decreasing = FALSE) # obtendo o menor e o maior valor menor &lt;- idade[1] maior &lt;- idade[length(idade)] R1 &lt;- maior - menor # ou pelo minimo e máximo dos dados R2 &lt;- max(idade) - min(idade) paste(&quot;As duas medidas são iguais?&quot;, all.equal(R1,R2)) ## [1] &quot;As duas medidas são iguais? TRUE&quot; c(R1,R2) ## [1] 80 80 2.2.2.3 Coeficiente de variação \\(cv\\) Esta medida estatística muitas vezes é chamada de desvio padrão relativo e é uma medida padronizada de dispersão. Em alguns contextos é possível optar pelo cv ao invés do desvio padrão. Quanto maior for o coeficiente de variação, maior será a dispersão nos dados em torno da média. O cv é expresso como a divisão entre o desvio padrão e a média e pode ser calculado pela seguinte expressão. \\[cv_{amostral} = \\frac{S}{\\bar X}\\] e \\[cv_{populacional} = \\frac{\\sigma}{\\mu}\\] Vale salientar que o cv e o desvio padrão se aplicam a dados estritamente positivos. Interpretação: por ser uma medida adimensional, o cv é uma medida prática para compararar e interpretar a variabilidade entre dois conjuntos de dados de tipos diferentes e pode ser interpretada em termos percentuais. Veja o exemplo a seguir. Exemplo 2.9 Vamos determinar e interpretar o coefiente de variação da receita das IES em relação ao total de técnicos. base_ies %&gt;% dplyr::summarise(`Média receita` = mean(VL_RECEITA_PROPRIA), `Média técnicos` = mean(QT_TEC_TOTAL), `CV receita` = c(sd(VL_RECEITA_PROPRIA) / mean(VL_RECEITA_PROPRIA)), `CV técnicos` = sd(QT_TEC_TOTAL) / mean(QT_TEC_TOTAL)) %&gt;% round(., digits = 3) ## Média receita Média técnicos CV receita CV técnicos ## 1 145378180 168.1 2.867 3.475 Os cálculos mostram uma enorme variabilidade dos dados das IES, pois o cv para receita é 286% e para total de técnicos é 347%. Neste caso, temos indicativos de que a dispersão dos dados é grande. Isso pode ser explicado pelo tamanho das IES. Por exemplo, as federais são minoria na base de dados, mas possuem grande quantidade de técnicos e alto aporte de receita, enquanto as IES menores, geralmente privadas possuem menor número de técnicos e menor receita. Estados como São Paulo apresentam números muito grandes em relação ao restante do país. 2.2.3 Outras medidas Existem muitas estatísticas úteis para analisar dados numéricos que nem sempre são exploradas, entre elas temos os quartis, decis, percentis e amplitude interquartis. 2.2.3.1 Quartis, decis e percentis Quartis: Chamamos de quartil qualquer uma das três medidas que separam um conjunto de dados ordenado em q partes iguais. Quartil vem de 1/4 (um quarto dos dados). A mediana que já vimos representa o segundo quartil. Costumamos representar os quatis pela letra Q seguida de um número tais como: \\(Q1\\): primeiro quartil representa 25% da amostra ordenada; \\(Q2\\): segundo quartil ou mediana representa 50% da amostra ordenada; \\(Q3\\): terceiro quartil representa 75% da amostra ordenada; Decil: O raciocínio é o mesmo dos quatis. Decis são medidas que dividem o conjunto de dados em 10 partes iguais. O primeiro decil representa 10% dos dados, o segundo 20% e assim por diante. Percentil: De forma análoga aos decis, os percentis dividem o conjunto de dados em 100 partes iguais. Para obter estas estatísticas seguimos o mesmo racional da mediana, dividindo os dados em partes iguais e identificando os elementos do centro e borda. No R podemos calcular facilmente estas estatísticas pela função quantile() para qualquer tamanho de faixa e por summary() para os quartis. Sempre que desejar fazer um raio-x dos dados é sugerido fazer uma análise de quartil, decil ou percentil, pois desta forma ficará evidente qualquer anomalia nos dados. 2.2.3.2 Amplitude interquartil A amplitude interquartil ou do inglês InterQuartile Range (IQR) é a medida de distância ou range entre o primeiro quartil \\(Q_1\\) e o terceiro \\(Q_3\\). Sua importância reside no fato de que ela representa os 50% dos dados centrais do conjunto de dados. \\[IQR = Q_3-Q_1\\] Junto com esta estatística surge também dois conceitos importantes que são os limites superiores \\(LS\\) e inferiores \\(LI\\) para decidir se determinado ponto é discrepante ou não. Uma dada medida é dita discrepante ou outlier quando ela está muito diferente da maioria das medidas realizadas. É demonstrado que no intervalo determinado por \\(LI=Q_1-1.5 \\times IQR\\) e \\(LS=Q_3+1.5 \\times IQR\\) temos 99% dos dados, assim qualquer valor que cair fora deste intervalo em geral, pode ser chamado de outlier. Exemplo 2.10 Vamos determinar se existe algum outlier no conjunto de dados das idades dos docentes das IES. base_docentes %&gt;% dplyr::summarise(Q1 = quantile(idade, probs = 0.25), Q2 = quantile(idade, probs = 0.50), Q3 = quantile(idade, probs = 0.75), IQR = Q3 - Q1, LI = Q1 - 1.5*IQR, LS = Q3 + 1.5*IQR, Noutliers = sum(idade &gt; LS), Ntotal = n(), Pct = Noutliers / Ntotal) ## Q1 Q2 Q3 IQR LI LS Noutliers Ntotal Pct ## 1 36 43 52 16 12 76 951 392036 0.002426 Conforme a analise acima, vemos que apenas \\(\\frac{951}{392036} = 0,24\\%\\) dos docentes são outliers possuindo idade acima de 76 anos. Outliers possuem grande importância na estatística e nunca devem ser negligenciados, pois podem trazer informação valiosa para a análise. Existem muitas técnicas de detecção de outiers mais robustas que esta que vimos a partir dos quartis. Ao leitor interessado ver (Barnett and Lewis 1974) e para uma visão baseada em R ver (Komsta 2011). 2.2.3.3 Os cinco números Os cinco números são um conjunto de estatísticas composto por \\(Min, Q_1,Q_2,Q_3\\) e \\(Max\\), estas cinco estatísticas costumam ser suficientes para analisar a distribuição dos dados pois junta as estatísticas mais importantes, a mediana representando uma medida de centralidade, os quartis \\(Q1,Q3\\) representado medidas de dispersão e o mínimo e máximo que representam o range dos dados. É comum em estatística, juntarmos em uma tabela as principais estatísticas de uma variável numérica para interpretar sua relevância no contexto do estudo ou experimento em questão. Além do resumo dos cinco números, podemos adicionar outras estatísticas de nosso interesse. A função rnp_summary() em conjunto com rnp_freq() e rnp_summary_by() nos auxiliarão em muitas análises no curso deste livro. 2.2.3.4 Exercícios Ainda na base das IES, analise através de estatísticas de dispersão as questões a seguir. Exercício 2.9 A despesa anual com docentes é representada pela variável VL_DESPESA_PESSOAL_DOCENTE. Interprete estatísticas de dispersão para esta variável. estatisticas &lt;- c(&quot;Min&quot;,&quot;Q1&quot;,&quot;Media&quot;,&quot;Mediana&quot;,&quot;Q3&quot;,&quot;Max&quot;,&quot;cv&quot;) tb &lt;- rnp::rnp_summary(base_ies$VL_DESPESA_PESSOAL_DOCENTE)[estatisticas] knitr::kable(t(tb), booktabs = TRUE, format = tb_formata, digits = 3, caption = &quot;ex: Média e mediana técnicos (IES)&quot;) %&gt;% kableExtra::kable_styling(latex_options = &quot;hold_position&quot;) Tabela 2.9: ex: Média e mediana técnicos (IES) Min Q1 Media Mediana Q3 Max cv 1 696484 66328326 3295507 37257632 7600039210 3.661 Solução. Como podemos ver na tabela acima, o desvio padrão da despesa com pessoal é muito grande e isso se deve ao fato de que existe grande variabilidade nos dados. O coeficiente de variação (cv) mostra que esta variabilidade em torno da média é de 366,1 por cento. Temos ainda que 75 por cento (\\(Q_3\\)) das IES gastam com docentes anualmente até R$37.257.632. Exercício 2.10 Qual o top 10 IES com maior receita própria? Dica: Para resolver este problema, isolamos as variáveis NO_IES e VL_RECEITA_PROPRIA ordenada da maior para a menor. base_ies %&gt;% dplyr::transmute(NomeIES = NO_IES, ReceitaPropria = VL_RECEITA_PROPRIA) %&gt;% dplyr::arrange(desc(ReceitaPropria)) %&gt;% head(n = 10) %&gt;% knitr::kable(booktabs = TRUE, format = tb_formata, digits = 3) %&gt;% kableExtra::kable_styling(latex_options = &quot;hold_position&quot;) NomeIES ReceitaPropria FACULDADE DE ADMINISTRAÇÃO, CIÊNCIAS, EDUCAÇÃO E LETRAS 6248050290 FACULDADE MAURÍCIO DE NASSAU DE MOSSORÓ 4434457964 FACULDADE MAURÍCIO DE NASSAU DE MACEIÓ 4024118925 Faculdade Fernanda Bicchieri 4000452319 FACULDADE ESTÁCIO DE SÁ DE VILA VELHA 3131607366 FACULDADE ESTÁCIO DE SÁ DE CAMPO GRANDE 3131607366 FACULDADE ESTÁCIO DE SÁ DE GOIÁS 3131607366 CENTRO UNIVERSITÁRIO ESTÁCIO JUIZ DE FORA - ESTÁCIO JUIZ DE FORA 3131607366 UNIVERSIDADE ESTÁCIO DE SÁ 3131607366 FACULDADE ESTÁCIO DE SÁ DE OURINHOS 3131607366 2.2.4 Gráficos para uma variável numérica Existem muitos tipos de gráficos, porém para uma variável listamos os três que consideramos mais importantes. 2.2.4.1 Histogramas Os histogramas são um tipo de gráfico de barras para variáveis numéricas e servem principalmente para analisar visualmente a centralidade e dispersão dos dados. No processo de construção do histograma, os dados são categorizados em classes e as frequências são contadas. No eixo horizontal geralmente são mostradas as classes e eixo vertical as frequências que podem ser absolutas ou relativas. Exemplo 2.11 Vamos criar um histograma para a variável idade dos docentes. p &lt;- ggplot2::ggplot(base_docentes, aes(x = idade)) p + ggplot2::theme_gray() + ggplot2::geom_histogram(colour=&#39;white&#39;, bins = 10) + ggplot2::labs(y = &quot;Frequência&quot;, x = &quot;Faixa de idade&quot;, fill = NULL, title = &quot;&quot;) + ggplot2::scale_x_continuous( breaks=seq(10, 90, 10), labels = seq(10, 90, 10) ) + ggplot2::theme(axis.line = element_blank()) Figura 2.8: Histograma idade do docente Veja que a figura 2.8 evidencia que as maiores concentrações de docentes estão nas faixas de idade entre 30 e 50 anos. 2.2.4.2 Densidade Gráficos de densidade possuem aplicação semelhante aos histogramas, porém são mais indicados pata amostras grandes. Ele evidenciam a melhor curva que representam os dados. Este tipo de gráfico nos ajuda também a verificar a distribuição de probabilidade aproximada que os dados podem seguir. Exemplo 2.12 Vamos criar agora um gráfico de densidade para a variável idade dos docentes. p &lt;- ggplot2::ggplot(base_docentes, aes(x = idade)) p + ggplot2::theme_gray() + ggplot2::geom_density(adjust = 1) + ggplot2::labs(y = &quot;Densidade&quot;, x = &quot;Idade&quot;, fill = NULL, title = &quot;&quot;) + ggplot2::scale_x_continuous( breaks=seq(10, 90, 10), labels = seq(10, 90, 10)) + ggplot2::theme(axis.line = element_blank()) Figura 2.9: Densidade idade do docente Perceba na figura 2.8 como esperado, que a densidade dos dados está concentrada idade entre 30 e 50 anos. Porém, ela aponta uma elevação próxima a 50 anos apontando comportamento bimodal nos dados. 2.2.4.3 Box-Plot De longe o gráfico Box-plot ou para muitos, diagrama de caixa é o tipo mais completo de gráfico para variável numérica. Figura 2.10: Definindo um Box-plot A figura 2.10 ilustra os elementos que compõem um Box-plot. Perceba que visualmente ele contempla as estatísticas \\(Q_1\\), \\(Q_2\\) (mediana), \\(Q_3, IQR, LI,LS\\) e outliers. Com base nestas estatísticas, uma variável numéricas estará bem caracterizada. Exemplo 2.13 Ainda para os dados de idade, vamos montar um Box-plot p &lt;- ggplot2::ggplot(base_docentes, aes(y = idade)) p + ggplot2::theme_gray() + ggplot2::geom_boxplot(adjust = 1) + ggplot2::labs(x = &quot;&quot;, y = &quot;Idade&quot;, fill = NULL, title = &quot;&quot;) + ggplot2::coord_flip() + ggplot2::theme(axis.line.x = element_line(), axis.text.x = NULL, axis.line.y = element_blank()) Figura 2.11: Box-plot idade do docente Conforme vimos antes, idades acima de 76 anos são pontos atípicos na base de docentes, por isso no Box-plot estes pontos aparecem fora do limite superior de outliers na figura 2.20. 2.2.5 Gráficos para duas variáveis numéricas Os principais gráficos para analisar a relação entre duas variáveis são o gráfico de pontos ou scatterplot e o gráfico de linhas, através deles é possível analisar a relação conjunta entre as variáveis e determinar se uma influencia a outra de alguma forma. além destes, também podemos traçar gráficos de densidade para comparar as duas curvas. 2.2.5.1 scatterplot O gráfico de pontos é um gráfico bidimensional onde cada eixo representa os valores de uma variável. Este tipo de gráfico é ótimo para analisar a correlação de duas variáveis bem como sua dispersão, pois cada ponto representa a ligação dos elementos das duas variáveis. Exemplo 2.14 Para lustrar vamos traçar um gráfico de pontos para a receita próprias das IES pelo total de técnicos na base das IES. Obs.: como temos muitos autliers na variável de receita própria, vamos limitar a 10.000.000 (dez milhões de reais por ano) p &lt;- base_ies %&gt;% dplyr::mutate(ReceitaPropria = VL_RECEITA_PROPRIA, TotalTecnicos = QT_TEC_TOTAL) %&gt;% dplyr::filter(ReceitaPropria &lt;= 10000000) %&gt;% ggplot2::ggplot(aes(x = TotalTecnicos, y = ReceitaPropria)) p + ggplot2::theme_gray() + ggplot2::geom_point() + ggplot2::labs(x = &quot;Total técnicos&quot;, y = &quot;Receita própria&quot;, fill = NULL, title = &quot;&quot;) + ggplot2::theme(axis.line.x = element_line(), axis.text.x = NULL, axis.line.y = element_blank()) Figura 2.12: Gráfico de pontos total de técnicos versus receita própria 2.2.5.2 Grafico de linhas O gráfico de linhas possui aplicação para duas variáveis contínuas e também para séries temporais, onde um dos eixos é uma variável numérica de data. p &lt;- base_ies %&gt;% dplyr::mutate(ReceitaPropria = VL_RECEITA_PROPRIA, TotalTecnicos = QT_TEC_TOTAL) %&gt;% dplyr::filter(TotalTecnicos &lt; 100) %&gt;% ggplot2::ggplot(aes(x = TotalTecnicos, y = ReceitaPropria)) p + ggplot2::theme_gray() + ggplot2::geom_line() + ggplot2::labs(x = &quot;Total técnicos&quot;, y = &quot;Receita própria&quot;, fill = NULL, title = &quot;&quot;) + ggplot2::theme(axis.line.x = element_line(), axis.text.x = NULL, axis.line.y = element_blank()) Figura 2.13: Gráfico de pontos total de técnicos (&lt;50) versus receita própria 2.3 Variáveis categóricas versus numéricas O trabalho estatístico muitas vezes exige que alguma variável numérica seja categorizada ou analisada em conjunto com alguma variável categórica. Todas as técnicas vistas até agora, tanto as medidas estatísticas quanto os gráficos podem ser analisados em conjunto para gerar informação. 2.3.1 Categorizando variáveis numéricas. Em R podemos agrupar uma variável numérica de muitas formas, umas delas é através das estatísticas de quartis, decis ou percentis dependendo do tamanho da base, com a função quantile() combinada com a função cut(). Outra forma é através do conhecimento próprio do analista com os operadores relacionais do R: &lt;, &gt;, &gt;=, &lt;=, ==, !=, %in% combinadas com ifelse(). Exemplo 2.15 Vamos categorizar a variável receita próprias das IES de duas formas distintas: por quartis e por operadores relacionais com quatro faixas. ## Categorizando por quartis base_ies &lt;- base_ies %&gt;% dplyr::mutate(ReceitaPropria = VL_RECEITA_PROPRIA, TotalTecnicos = QT_TEC_TOTAL) fx_receita_q &lt;- cut(base_ies$ReceitaPropria, breaks = round(quantile(base_ies$ReceitaPropria)), dig.lab = 10, include.lowest = TRUE) rnp::rnp_freq(fx_receita_q, sortd = FALSE) %&gt;% knitr::kable(digits = 3, booktabs = TRUE, format = tb_formata, caption = &quot;Categorização por quartis&quot;) %&gt;% kableExtra::kable_styling(latex_options = &quot;hold_position&quot;) Tabela 2.10: Categorização por quartis classe fa fr Faa Fra 0–1389966 612 0.25 612 0.25 1389966–7429221 612 0.25 1224 0.50 7429221–61258594 612 0.25 1836 0.75 61258594–6248050290 612 0.25 2448 1.00 ## Categorização por ifelse com operadores relacionais fx_receita_r &lt;- ifelse(base_ies$ReceitaPropria &lt;= 1200000, &quot;A.-1200000&quot;, ifelse(base_ies$ReceitaPropria &lt;= 5000000, &quot;B.1200000 a 5000000&quot;, ifelse(base_ies$ReceitaPropria &lt;=35000000, &quot;C.5000000 a 35000000&quot;,&quot;D.35000000+&quot;))) rnp::rnp_freq(fx_receita_r, sortd = FALSE) %&gt;% knitr::kable(digits = 3, booktabs = TRUE, format = tb_formata, caption = &quot;Categorização por operadores relacionais&quot;) %&gt;% kableExtra::kable_styling(latex_options = &quot;hold_position&quot;) Tabela 2.10: Categorização por operadores relacionais classe fa fr Faa Fra A.-1200000 571 0.233 571 0.233 B.1200000 a 5000000 500 0.204 1071 0.438 C.5000000 a 35000000 635 0.259 1706 0.697 D.35000000+ 742 0.303 2448 1.000 No primeiro caso, criamos os cortes utilizando os quartis da variável e em seguida passamos estes cortes para a função cut() que por sua vez particionou a variável de acor com as partes informadas pelo argumento breaks. Desta forma fica mais rápido a categorização, mas o analista não tem como personalizar as faixas. Para atender a esta limitação o segundo método ajuda a customizar as faixas de acordo com a preferência ou necessidade. Embora exija um pouco mais de código, esta última opção é mais flexível. 2.3.2 Medidas estatísticas por agrupamento Em muitas situações da análise de dados, estamos interessados em analisar a influência de uma variável categórica sob uma ou mais variáveis numéricas. Felizmente, a grande maioria das medidas estatísticas aprendidas até agora se aplicam a este tipo de análise que exige estatísticas agrupadas. Exemplo 2.16 Vamos calcular estatísticas descritivas de idade dos docentes (em anos) por escolaridade. base_docentes %&gt;% dplyr::group_by(escolaridade) %&gt;% dplyr::summarise(N = n(), Min = min(idade), Q1 = unname(quantile(idade, probs = 0.25)), Me = mean(idade), Md = median(idade), Q3 = unname(quantile(idade, probs = 0.75)), Max = max(idade) #Dp = sd(idade), #cv = sd(idade)/mean(idade) ) %&gt;% knitr::kable(digits = 2, booktabs = TRUE, format = tb_formata, caption = &quot;Estatísticas descritivas idade vs escolaridade&quot;) %&gt;% kableExtra::kable_styling(latex_options = &quot;hold_position&quot;) Tabela 2.11: Estatísticas descritivas idade vs escolaridade escolaridade N Min Q1 Me Md Q3 Max 1. Sem graduação 10 23 47.25 52.60 54 63 66 2. Graduação 4613 20 27.00 37.78 33 45 94 3. Especialização 72301 19 35.00 43.01 41 50 93 4. Mestrado 154285 22 34.00 42.81 41 50 90 5. Doutorado 160827 19 38.00 47.06 46 54 99 Em \\(Q3\\) temos que 75% dos docentes com Doutorado possuem idade até 54 anos. Vemos também alguns doutores excepcionais com idade mínima de 19 anos. A idade máxima registrada foi de 99 anos presente no grupos dos doutores. A categoria sem graduação tem dez indivíduos e é pouco representativa. # Como nossa rnp_summary, poderiamos fazer assim aggregate(idade ~ escolaridade, data = base_docentes, FUN = function(i) rnp::rnp_summary(i)) 2.3.3 Gráficos para categóricas vs numéricas Com apoio do pacote ggplot podemos combinar a maioria dos gráficos vistos até agora para analisar dados por grupo ou classes. Como citamos na seção 1.6 uma das ferramentas estatísticas é a análise bivariada e ela pode ser feita entre duas variáveis podendo ser de mesmo tipo ou de tipos diferentes Box-plot agrupado: Box-plots por categoria são muito informativos uma vez que resumem sete estatísticas fundamentais de uma variável continua conforma já vimos. Exemplo 2.17 Represente visualmente a análise da tabela 2.11 através de Box-plots. p &lt;- base_docentes %&gt;% ggplot2::ggplot(aes(x = escolaridade, y = idade, fill = escolaridade)) p + ggplot2::theme_gray() + ggplot2::geom_boxplot(show.legend = FALSE) + ggplot2::coord_flip()+ ggplot2::theme(axis.line.x = element_line(), axis.text.x = NULL, axis.line.y = element_blank()) Figura 2.14: Box-plot de idade vs escolaridade No Box-plot conseguimos ver que docentes com graduação apenas são minoria como visto na tabela e doutores são maioria. Notamos também que, com exceção daqueles sem graduação todos os grupos possuem dispersão parecida uma vez que a distância entre \\(Q_1\\) e \\(Q_3\\) é pequena. Para todos os graficos agrupados também é possível quebrar a visualização em um gráfico por categoria adicionando uma terceira variável com facet_wrap() . p &lt;- base_docentes %&gt;% ggplot2::ggplot(aes(x = sexo, y = idade, fill = escolaridade)) p + ggplot2::theme_gray() + ggplot2::geom_boxplot(show.legend = FALSE) + ggplot2::coord_flip()+ ggplot2::facet_wrap(escolaridade~.)+ ggplot2::theme(axis.line.x = element_line(), axis.text.x = NULL, axis.line.y = element_blank()) Figura 2.15: Box-plot de idade vs escolaridade por sexo Gráfico de densidade agrupado: é possível comparara várias curvas simultaneamente no mesmo gráfico para analisar a distribuição dos dados. Exemplo 2.18 Represente visualmente a análise da tabela 2.11 desta vez utilizando densityplot. p &lt;- base_docentes %&gt;% ggplot2::ggplot(aes(x = idade, fill = escolaridade)) p + ggplot2::theme_gray() + ggplot2::geom_density(alpha = 0.6) + ggplot2::theme(legend.position = &quot;right&quot;) + ggplot2::theme(axis.line.x = element_line(), axis.text.x = NULL, axis.line.y = element_blank()) + ggplot2::labs(x = &quot;Idade&quot;, y = &quot;Densidade&quot;, fill = NULL, title = &quot;&quot;) Figura 2.16: Densidade de idade vs escolaridade O resultado é um gráfico elegante e que indica precisamente a forma da distribuição dos dados. Agora quebrado por sexo. p &lt;- base_docentes %&gt;% ggplot2::ggplot(aes(x = idade, color = sexo, fill = escolaridade)) p + ggplot2::theme_gray() + ggplot2::geom_density(alpha = 0.6, show.legend = FALSE) + ggplot2::facet_wrap(~escolaridade)+ ggplot2::theme(axis.line.x = element_line(), axis.text.x = NULL, axis.line.y = element_blank()) + ggplot2::labs(x = &quot;Idade&quot;, y = &quot;Densidade&quot;, fill = NULL, title = &quot;&quot;) Figura 2.17: Densidade de idade vs escolaridade por sexo Gráfico de colunas agrupadas: é possível assim, como nos dois últimos exemplos, gerar gráficos e coluna agrupadas e fazer a quebra adicionando uma terceira variável. p &lt;- base_docentes %&gt;% ggplot2::ggplot(aes(x = escolaridade, y = idade, fill = sexo)) p + ggplot2::theme_gray() + ggplot2::geom_col(show.legend = TRUE, position = &quot;dodge&quot;) + ggplot2::theme(legend.position = &quot;bottom&quot;) + ggplot2::coord_flip()+ ggplot2::theme(axis.line.x = element_line(), axis.text.x = NULL, axis.line.y = element_blank()) Figura 2.18: Colunas de idade vs escolaridade por sexo Histogramas agrupados: Histogramas também são agrupáveis segundo as categorias da variável. p &lt;- base_docentes %&gt;% ggplot2::ggplot(aes(x = idade, fill = escolaridade)) p + ggplot2::theme_gray() + ggplot2::geom_histogram(bins = 10, show.legend = FALSE) + ggplot2::facet_wrap(.~escolaridade)+ ggplot2::theme(axis.line.x = element_line(), axis.text.x = NULL, axis.line.y = element_blank()) Figura 2.19: Histograma de idade vs escolaridade 2.4 Medidas de associação Análises univariadas são muito úteis para determinarmos particularidades de dados porém, em muitas situações, desejamos medir relações de interdendência entre duas ou mais variáveis. Como vimos em gráficos para duas variáveis numérias; gráficos para duas variáveis categóricas e também em tabelas de contingência, é possivel extrair carcaterísticas importantes dos valores e/ou das classes de cada variáveil. Contudo, queremos quantificar a relação global de duas ou mais variáveis e neste sentido, as medidas de associação tem papel fundamental. Suponha que desejamos determinar de a variável idade dos docentes está associada à escolaridade ou se o total de técnicos está correlacionado com a receita total da IE. Trataremos nesta sessão algumas medidas de associação entre duas variáveis categóricas onde trabalharemos com as estatísticas \\(\\chi^2\\) (Qui-quadrado), \\(V\\) de Cramer, \\(C\\) coeficiente de contingência. Para as variáveis numéricas trabalharemos com as estatísticas de correlação \\(\\rho\\) de Peason, Coeficiente de correlação rank de Spearman e Medidas de concordância e discordância de pares. 2.4.1 Associação entre duas variáveis discretas Duas variáveis discretas são ditas independentes ou não associadas quando as observações de uma não influenciam as observações da outra. Por exemplo, quando duas pessoas jogam uma moeda separadamente dez vezes, o resultados da primeira pessoa não são afetados pelos resultados da segunda pessoa. 2.4.1.1 Estatística \\(\\chi^2\\) A estatística \\(\\chi^2\\) é muito utilizada para quantificar a associação global de duas variáveis categóricas dispostas em uma tabela de contingência com \\(k \\times l\\) linhas vs colunas. Esta estaísticas é dada por: \\[\\chi^2 = \\sum_{i=1}^{k} \\sum_{j=1}^{l} \\frac{(n_{ij} - \\widetilde{n}_{ij})^2}{\\widetilde{n}_{ij}}\\] onde \\(\\widetilde{n}_{ij}\\) é a frequência esperada de \\((x_i;y_j)\\) dada pelo produto das frequências absolutas marginais e calculado por \\[\\widetilde{n}_{ij} = \\frac{n_{i+}\\times n_{+j}}{n}\\] Para que a estatística seja confiável, os seguintes pressupostos devem ser respeitados: A amostra deve ser aleatória; Todas as frequências esperadas são maiores ou iguais a 1; Não mais de 20% das frequências esperadas são inferiores a 5; Caso os desvios entre as frequências observadas e esperadas seja alto temos evidência de associação forte porque as frequências relativas esperadas são calculadas assumindo independência entre as duas variáveis. Desta forma, se o posto ocorrer, ou seja, se as frequências relativas observadas e esparadas são idênticas ou similares a associação é fraca e as variáveis são independentes. O range da estatística está limitado a \\[0 \\le \\chi^2 \\le n\\times(min(k,l)-1)\\] Assim, uma forma de verificar a força da associação é comparar o valor de \\(\\chi^2\\) calculado com o valor máximo que \\(\\chi^2\\) pode assumir, ou seja \\(n\\times(min(k,l)-1)\\) onde \\(n\\) é o total geral. Esta métrica depende unicamente do tamanho da amostra e total de classes de cada variável da tabela de contingência. É provado que a estatística \\(\\chi^2\\) segue uma distribuição qui-quadrado com \\(\\nu\\) graus de liberdade calculados com base no total de classes das variáveis da tabela de contingência \\(\\nu = (k-1)\\times (l-1)\\). Veremos em testes de hipóteses como quantificar a incerteza do teste de \\(\\chi^2\\) através do p-valor do teste. Por hora, apresentamos apenas a estatística geral. Exemplo 2.19 Vamos calcular a força da associação entre as variáveis da tabela 2.3. Solução. Iniciamos calculando as frequências relativas esperadas \\(f_{ij}\\) \\(f_{11} = 10 \\times 179856 / 392036 = 4.6\\) \\(f_{12} = 10 \\times 212180 / 392036 = 5.4\\) \\(f_{21} = 4613 \\times 179856 / 392036 = 2116.0\\) \\(f_{22} = 4613 \\times 212180 / 392036 = 2497.0\\) \\(f_{31} = 33169.8\\) \\(f_{32} = 39131.2\\) \\(f_{41} = 70782.0\\) \\(f_{42} = 83503.0\\) \\(f_{51} = 73783.3\\) \\(f_{52} = 87043.7\\) \\(\\chi^2 = \\frac{(3-4.6)^2}{4.6} + \\frac{(7-5.4)^2}{5.4}+...+\\frac{(87015-87043.7)^2}{87043.7} = 655.0\\) Agora calculamos o valor máximo que \\(\\chi^2\\) pode assumir \\(392036 \\times (min(i=5,j=2)-1) = 392036\\). Como \\(655.0\\) está muito longe de \\(392036\\) podemos afirmar que não existe associação forte entre escolaridade e sexo dos docentes, ou seja estas duas variáveis são independentes. Em R podemos calcular a estatística e as frequências esperadas através da função chisq.test() em conjunto com a função table(). Exemplo 2.20 Repita a análise anterior agora com o R. Solução. Vamos resolver passo a passo e depois com a função chisq.test() # Sem utilizar a chisq.test() observado &lt;- table(base_docentes$escolaridade, base_docentes$sexo) observado ## ## 1. Feminino 2. Masculino ## 1. Sem graduação 3 7 ## 2. Graduação 1848 2765 ## 3. Especialização 30579 41722 ## 4. Mestrado 73614 80671 ## 5. Doutorado 73812 87015 esperado &lt;- outer(rowSums(observado), colSums(observado), &quot;*&quot;)/sum(observado) esperado ## 1. Feminino 2. Masculino ## 1. Sem graduação 4.588 5.412 ## 2. Graduação 2116.325 2496.675 ## 3. Especialização 33169.833 39131.167 ## 4. Mestrado 70781.977 83503.023 ## 5. Doutorado 73783.277 87043.723 sum((observado-esperado)^2/esperado) ## [1] 647.2 # Com a chisq.test() t1 &lt;- chisq.test(observado) t1$expected ## ## 1. Feminino 2. Masculino ## 1. Sem graduação 4.588 5.412 ## 2. Graduação 2116.325 2496.675 ## 3. Especialização 33169.833 39131.167 ## 4. Mestrado 70781.977 83503.023 ## 5. Doutorado 73783.277 87043.723 t1$statistic ## X-squared ## 647.2 # Range sum(observado)*(min(dim(observado))-1) ## [1] 392036 2.4.1.2 Estatística \\(V\\) de Cramér Aestatística \\(\\chi^2\\) possui uma fragilidade que pode dificultar a interpretação, pois ela depende do range e este por sua vez depende do tamanho da amostra e da quantidade de classes em cada variável. A estatítica \\(V\\) surge como uma forma de padronização da estatística \\(\\chi^2\\) e é calculada por: \\[V = \\sqrt{\\frac{\\chi^2}{n \\times (min(k,l)-1)}}\\] Esta estatística torna a interpretação de \\(\\chi^2\\) mais simples, pois seu retorno é um número menor ou igual a uma unidade e quanto mais próximo de um, mais forte será a associação entre as duas variáveis. Tabelas de interpretação de estatísticas de associação como \\(V\\) são questionáveis uma vez que o nível de associação pode variar de acordo com tipo de estudo, área de pesquisa ou até preferência do pesquisador. Porém, algunas autores se guiam pelas faixas da tabela 2.12 para interpretar o nível da associação entre duas variáveis numa tabela de contingência. Estes valores são adapatados de (Gravetter and Wallnau 2016). Tabela 2.12: Interpretação da associação por V e C Faixa Interprecao 0.00–0.10 muito fraca 0.10–0.30 fraca 0.30–0.50 moderada 0.5 &gt; forte Exemplo 2.21 Utilizando a estatística \\(V\\) avalie a associação das variáveis do exemplo anterior. Solução. Temos que \\(\\chi^2 = 647.2\\), logo \\(V = \\sqrt{\\frac{\\chi^2}{392036 \\times (min(5,2)-1)}}\\) \\[V = \\sqrt{\\frac{647.2}{392036 \\times (min(5,2)-1)}} = \\sqrt{\\frac{647.2}{392036 \\times (2-1)}} = 0.0406\\] Como \\(V = 0.0406 &lt; 0.10\\) concluimos que não existe associação estatísticamente significativa entre escolaridade e sexo. Exercício 2.11 A base de dados dm_curso possui as variáveis DESC_IN_MATERIAL_BRAILLE e DESC_IN_MATERIAL_TATIL que se referem a recursos extras disponibilizados para os cursos. Verifique se estas variáveis estão associadas através das estatísticas \\(\\chi^2\\) e \\(V\\) Solução. Primeiro determinamos a esttaística \\(\\chi^2\\) data(dm_curso, package = &quot;rnp&quot;) # Tabela de contingência observado &lt;- table(dm_curso$DESC_IN_MATERIAL_BRAILLE, dm_curso$DESC_IN_MATERIAL_TATIL) # Com a chisq.test() t1 &lt;- chisq.test(observado) # Estatística e Range t1$statistic ## X-squared ## 52186 sum(observado)*(min(dim(observado))-1) ## [1] 71386 # O valor da estatística está próximo do Range. Temos indicios fortes de associação. Vamos calcular a estatística \\(V\\) \\[V = \\sqrt{\\frac{52186}{ 35693 \\times (min(3,3)-1)}} = \\sqrt{\\frac{52186}{35693 \\times (3-1)}} = 0.8550\\] Como \\(V\\) está muito acima de 0.50 logo, temos evidẽncias de que estas duas variáveis são fortemente associadas. Perceba que o próprio nome de cada variável contém um indicativo de associação uma vez que espera-se que materiais para aulas em braile devam conter itens de táteis. Aqui o analista entra com o senso de negócio para confirmar se as estatísticas fazem sentido prático na validação das hipóteses de pesquisa. 2.4.1.3 Estatística \\(C\\) coeficiente de contingência O coeficiente de contingêcia é outra medida de associação que depende da estatística \\(\\chi^ 2\\) e foi pensada para ser uma versão corrigida da estatística \\(\\chi^2\\). Os valor de \\(C\\), assim como os de \\(V\\) estão no intervalo \\([0,1]\\) e quanto maior mais forte será a associação entre as duas variáveis na tabela de contingência. \\[C = \\sqrt{\\frac{min(k,l)}{min(k,l)-1}} \\times \\sqrt{\\frac{\\chi^2}{\\chi^2 + n}} \\] Estas três estatísticas de associação podem ser calculadas pela função rnp::rnp_associacao() no nosso pacote ou atrvés da função vcd::assocstats() do pacote vcd. Exercício 2.12 Vamos deterinar as estatísticas \\(\\chi^2\\), \\(V\\) e \\(C\\) para o último exemplo. Solução. Com a função rnp::rnp_associacao() temos que: data(dm_curso, package = &quot;rnp&quot;) rnp::rnp_associacao(x = dm_curso$DESC_IN_MATERIAL_BRAILLE, y = dm_curso$DESC_IN_MATERIAL_TATIL) ## Qui-quadrado V-Cramer C-Contingencia ## 52185.5662 0.8550 0.9438 2.4.2 Duas ou mais variáveis numéricas Na análise bivariada ou multivariada de variáveis numéricas, a covariância e a correlação tem papel fundamental. Ambas se assemelham pelo fato de que medem a direção da relação entre duas variáveis ao longo de seus pontos. As relações mais comuns são ambas as variáveis crescem, ambas decrescem, uma decresce e a outra cresce. A diferença mais significativa entre a covariância e a correlação é que a primeira oferece um valor absoluto variando de acordo com os dados, graças a isso não tem como estimar a força de uma relação linear. É aí que entra a correlação. Em R a covariância pode ser calculada por var() e cov() e a correção por cor() e se aplica a bases com mais de 2 variáveis numéricas. 2.4.2.1 Covariância O conceito de covariância pode ser aplicado tanto a conjunto de dados como a variáveis aleatórias. Quando aplicada a duas variáveis \\(X\\) e \\(Y\\) é expressa por: \\[Cov(X,Y) = \\frac {\\sum_{i=1}^N(X_i-\\bar X)(Y_i - \\bar Y)}{N-1}, i=1,..,N\\] Sendo que \\(\\bar X\\) e \\(\\bar Y\\) são as médias das variáveis X e Y. Exemplo 2.22 Vamos calcular a covariância para TotalTecnicos e ReceitaProprianos dados das IES base_ies %&gt;% dplyr::select(TotalTecnicos, ReceitaPropria) %&gt;% cov() %&gt;% knitr::kable(booktabs = TRUE, format = tb_formata, caption = &quot;Análise de covariância&quot;) %&gt;% kableExtra::kable_styling(latex_options = &quot;hold_position&quot;) Tabela 2.13: Análise de covariância TotalTecnicos ReceitaPropria TotalTecnicos 341089 14066046853 ReceitaPropria 14066046853 173738053485884832 Note que os números são extremamente grandes e tudo que podemos tirar é que a covariância é positiva entre as duas variáveis, mas não conseguimos estimar a força desta relação. Os elementos da diagonal principal da matriz de covariâncias representam a variãncia de cada variável e os valores fora da diagonal são covariâncais. A matriz é espelhada e para interpretá-la basta ler acima ou abaixo da diagonal principal. 2.4.2.2 Correlação de Pearson A correlação linear ou de Pearson é uma estatística padronizada que varia de \\(-1\\) a \\(1\\) e expressa a relação linear entre duas variáveis numéricas. A correlação é expressa pela letra grega \\(\\rho\\) e é dada pela seguinte expressão matemática: \\[\\rho = \\frac {\\sum_{i=1}^N(X_i-\\bar X)(Y_i - \\bar Y)}{\\sqrt{\\sum_{i=1}^N(X_i-\\bar X)^2} \\times \\sqrt{\\sum_{i=1}^N(Y_i-\\bar Y)^2}}=\\frac{Cov(X,Y)}{\\sqrt{S^2(X) \\times S^2(Y)}}, \\\\ i=1,..,N\\] Em resumo, esta formula aparentemente complicada diz que a correlação é resultado da covariância dividida pela raiz quadrada do produto das variâncias de cada variável. Figura 2.20: Tendência da correlação A figura 2.20 ilustra a relação entre duas variáveis \\(X\\) e \\(Y\\). Da esquerda para a direita temos correlação linear negativa forte (tende a \\(-1\\)), correlação fraca (tende a \\(0\\)) e correlação linear positiva forte (tende a \\(+1\\)). Como regra geral, costuma-se considerar a distribuição expressa na tabela 2.14 para interpretar a correlação. A mesma se aplica para negativa ou positiva bastando apenas dizer estar alerta ao sinal de \\(\\rho\\). Tabela 2.14: Interpretação da correlação Faixa Interprecao 0.00–0.19 muito fraca 0.20–0.39 fraca 0.40–0.69 moderada 0.70–0.89 forte 0.90–1.00 muito forte Exemplo 2.23 Para o exemplo anterior, determinar e interpretar a correlação entre as duas variáveis. Incluia a variével DespesaPesquisa. base_ies %&gt;% dplyr::transmute(TotalTecnicos = QT_TEC_TOTAL, ReceitaPropria = VL_RECEITA_PROPRIA, DespesaPesquisa = VL_DESPESA_PESQUISA) %&gt;% cor(method = &quot;pearson&quot;) %&gt;% round(digits = 3) %&gt;% knitr::kable(booktabs = TRUE, format = tb_formata, caption = &quot;Análise de correlação&quot;) %&gt;% kableExtra::kable_styling(latex_options = &quot;hold_position&quot;) Tabela 2.15: Análise de correlação TotalTecnicos ReceitaPropria DespesaPesquisa TotalTecnicos 1.000 0.058 0.292 ReceitaPropria 0.058 1.000 0.064 DespesaPesquisa 0.292 0.064 1.000 Note agora que faz mais sentido estimar a força da relação linear entre as variáveis utilizando a correlação. No nosso exemplo, uma correlação linear de 0.047 entre TotalTecnicos e ReceitaPropria nos diz que a relação linear entre estas duas variáveis é muito fraca. O mesmo se aplica à variável DespesaPesquisa em relação à variável TotalTecnicos com 0.190. Estas três variáveis não possuem correlação forte entre si. 2.4.2.3 Correlação rank de Spearman Para ilustrar esta correlação, vamos imaginar que dois jurados avaliem a qualidade do ensino em cada uma das IES mapeadas no censo, por algum método de forma independente e atribuam uma nota numérica de 0 a 100 onde notas baixas sejam ruins e altas sejam boas. Vamos chamar esta nota de escore e definir por \\(x_i\\). Ao ordenarmos todas as IES pelas notas das maiores para as menores teremos um rank que vai de 1 para o peimeiro lugar até o total de IES (assumindo que não há empates). Ao selecionarmos uma IES qualqer do conjunto de dados, teremos dois ranks, \\(R(x_i)\\) e \\(R(y_i)\\) para ela e consequentemente uma diferença entre os ranks dada por \\(d_i = R(x_i) - R(y_i)\\). Por exemplo, se a UFPR teve os ranks 20 e 25, temos que \\(d_i = 20-25 = 5\\). O coeficiente de correlação rank de Spearman busca medir a força da associação entre os dois julgamentos dos dois jurados. Calculamos o coeficiente de correlação rank de Spearman por \\[ R = 1 - \\frac{6 \\times \\sum_{i = 1}^{n} d^2_i}{n \\times (n^2 - 1)}\\] Este tipo de correlação se aplica para variáveis contínuas e também ordinais e conforme já exposto, busca medir a correlação através dos ranks de cada variável e varia de \\(-1\\) a \\(+1\\). Quando \\(R=+1\\) temos que as duas variáveis foram rankeadas exatamente iguais (concordãncia ou associação perfeita) e \\(R=-1\\) quando ocorreu o oposto (inconcordância). Exemplo 2.24 Determinar e interpretar a correlação entre as duas variáveis TotalTecnicos e ReceitaPropria para as 10 primeiaras observações da base de dados dm_ies. temp &lt;- base_ies %&gt;% head(n = 10) %&gt;% dplyr::transmute(TotalTecnicos = QT_TEC_TOTAL, `R(xi)` = rank(-TotalTecnicos), ReceitaPropria = VL_RECEITA_PROPRIA, `R(yi)` = rank(-ReceitaPropria), di = `R(xi)`-`R(yi)`, di2 = di^2) # Tabela de exemplo knitr::kable(x = temp, booktabs = TRUE, format = tb_formata, caption = &quot;Análise de correlação de Spearman&quot;) %&gt;% kableExtra::kable_styling(latex_options = &quot;hold_position&quot;) Tabela 2.16: Análise de correlação de Spearman TotalTecnicos R(xi) ReceitaPropria R(yi) di di2 1574 3 6913132 7 -4 16 3206 1 63239902 6 -5 25 1429 4 3161937 10 -6 36 1721 2 4136205 8 -6 36 786 8 3458763 9 -1 1 1275 5 616991005 1 4 16 441 9 142785305 4 5 25 986 7 338035351 3 4 16 1062 6 487902230 2 4 16 246 10 100089191 5 5 25 # Calculando manualmente 1 - (6*sum(temp$di2))/(nrow(temp)*(nrow(temp)^2-1)) ## [1] -0.2848 # Calculando via R cor(temp$TotalTecnicos, temp$ReceitaPropria, method = &quot;spearman&quot;) ## [1] -0.2848 Concluimos que, via correlação de Spearman, temos associação negativa baixa entre total de técnicos e total de receita própria. Como vimos, o coeficiente de corralação é determinado pela função cor() padrão do R e ela cobre três tipos de coeficientes. Especialmente para o R NA PRÁTICA, criamos a função rnp_correlacao() que determina a correlação de Pearson, Spearman e Kendal. Esta última não abordaremos aqui, mas ela também é indicada para variáveis ordinais porém focada em pares concordantes versus discordantes. para os leitores interessados sugerimos (Kendall 1938). temp &lt;- base_ies %&gt;% dplyr::transmute(TotalTecnicos = QT_TEC_TOTAL, ReceitaPropria = VL_RECEITA_PROPRIA, DespesaPesquisa = VL_DESPESA_PESQUISA) rnp::rnp_correlacao(temp) %&gt;% knitr::kable(booktabs = TRUE, format = tb_formata, row.names = FALSE, caption = &quot;Correlação com rnp_correlacao()&quot;) %&gt;% kableExtra::kable_styling(latex_options = &quot;hold_position&quot;) Tabela 2.17: Correlação com rnp_correlacao() x y pearson spearman kendall TotalTecnicos DespesaPesquisa 0.2918 0.3724 0.2827 TotalTecnicos ReceitaPropria 0.0578 0.5253 0.3963 ReceitaPropria DespesaPesquisa 0.0642 0.1957 0.1583 2.5 Exercícios de estatística descritiva Objetivo: Fazer uma análise descritiva dos dados do censo da educação superior de 2017. Neste questionário, o analista será testado em uma situação real onde os conhecimentos práticos de estatística descritiva e R serão postos à prova. Instruções: Utilize tabelas, gráficos e tudo que aprendeu nos dois capítulos de estatística descritiva bem como revise os exemplos em R. Se preferir pode baixar os dados direto do site do INEP e em caso de dúvidas sobre as variáveis, consulte o dicionário de dados que vem junto dos dados baixados. Lembrando, temos os dados já prontos no pacote rnp, bastando apenas fazer o carregamento. Dados rnp::dm_ies - Estes são dados das Instituições de Ensino Superior do brasil; Dados rnp::dm_curso - Dados sobre os cursos de nível superior das IES; Dados rnp::dm_docente - Dados dos docentes de ensino superior; Se for baixar os dados do INEP veja a ajuda das funções rnp::rnp_get_inep_censo() e rnp::rnp_get_classes_inep() para ver como baixar os dados e aplicar a descrição das categorias das variáveis. Exercício 2.13 Verifique as três bases de dados e explore: Verifique a estrutura dos dados; Quantas variáveis e observações cada uma tem? Quais os tipos de dados cada uma tem (character, fator, etc.)? Quais os tipos de variáveis (numérica, categórica, etc.)? Exercício 2.14 Analisar informações relevantes sobre as instituições de ensino superior focando nas seguintes perguntas: Qual a distribuição de frequências das IES por categoria administrativa e por organização acadêmica? Qual a distribuição das IES por estado e região; Qual a quantidade de funcionários técnico-administrativos por estado e por região; Qual o volume de receita e de despesas total das IES no período por estado? Quais os top 10 estados com maior percentual de saldo (dinheiro que sobra depois de pagar as despesas em relação ao total de receita)? Quais os top 10 estados que possuem maior investimento em pesquisa nas suas IES? Faça um resumo descritivo das variáveis de receita e despesas e verifique pontos atípicos; Existe correlação entre as receitas e despesas das IES? Represente por Box-plot a receita das IES por UF e por região. Quais merecem atenção? Exercício 2.15 Analisar informações relevantes sobre os cursos superiores. Quais os top 10 cursos com mais vagas no Brasil? Quais os top 10 cursos com maiores taxas de conclusão em relação ao total de vagas? Analise o número de vagas, ingressos, matrículas e concluintes por UF utilizando o resumo dos cinco números? Qual a taxa média de conclusão por UF onde existe a oferta? Verifique a correlação entre no total de vagas e total de ingressos. Utilize a estatística \\(V\\) de Cramér e o coeficiente de contingência para verificar se existe associação entre as variáveis categoria administrativa, grau acadêmico e organização escolar duas a duas. Exercício 2.16 Obter informações relevantes sobre os docentes. Qual a distribuição de docentes por Categoria Administrativa e por escolaridade? E por regime de trabalho e sexo? Qual a idade média dos docentes por sexo e escolaridade? Mostre através de Box-plots ou histogramas. Verifique se existe associação entre categoria administrativa e raça ou entre raça e escolaridade Referências "],
["introducao-a-probabilidade-com-r.html", "Capítulo - 3 Introdução à probabilidade com R 3.1 Combinatória 3.2 Probabilidade 3.3 Variáveis aleatórias 3.4 Distribuições de probabilidade", " Capítulo - 3 Introdução à probabilidade com R Com a popularização da internet e o fácil acesso à informação e aos serviços online, o e-commerce tem crescido rapidamente. As pessoas querem mais comodidade e agilidade para obter seus produtos porém, junto com isso surgem alguns riscos entre eles, a exposição de dados e as fraudes online. Como o volume de transações (chamemos assim uma operação de compra e/ou venda online) online está cada dia maior, torna-se humanamente impossível tratar cada caso manualmente como era feito no passado. É aí que surge a necessidade de análises de transações de forma automática baseada em alguns critérios. Estes critérios podem ser variáveis tais como perfil de compras do cliente, dados geográficos entre outros e são organizados nos chamados modelos de risco de fraude. Estes modelos nada mais são que fórmulas estatísticas baseadas na teoria das probabilidades criadas com o objetivo de medir, com base nesta conjuntura de critérios, qual a probabilidade de uma transação ser fraudulenta ou não. Além de aplicações no e-commerce, modelos estatísticos são largamente aplicados nos segmentos bancários cobrindo risco de crédito e de mercado, no segmento de seguros, na previsão do tempo, no mercado financeiro e nas pesqusisas médicas, entre outros. Todos estes campos onde se pode aplicar modelos estatísticos estão inseridos no contexto de que existe certa aleatoriedade nos eventos ou seja, mesmo estando em condições semelhantes resultados distintos podem ocorrer. Os princípios da teoria das probabilidades dão suporte para a compreensão e formulação destes modelos e por isso se torna indispensável para o trabalho estatístico. É através da teoria da probabilidade que buscamos quantificar a incerteza envolvida nestes fenômenos e garantir usabilidade prática dos seus resultados. Diferentemente do módulo anterior, neste módulo teremos mais equações e exemplos teóricos pois exige maior detalhamento da teoria das probabilidades, mas sempre que possível analisaremos situações com dados reais. No final deste módulo você será capaz de: Revisar noções de análise combinatória; Entender e definir probabilidade, epaço amostral, eventos e independência; Compreender os conceitos de probabilidade, probabilidade condicional e total Entender o teorema de Bayes; Entender e definir variável aleatória discreta e contínua; Conhecer e distinguir as principais distribuições de probabilidades discretas e contínuas; Resolver problemas de probabilidades em geral. 3.1 Combinatória 3.1.1 Fatorial e princípio multiplicativo 3.1.2 Arranjo e permutação 3.1.3 Combinação 3.2 Probabilidade 3.2.1 Definições 3.2.2 Probabilidade condicional e teorema de Bayes 3.2.3 Independência 3.3 Variáveis aleatórias 3.4 Distribuições de probabilidade "],
["referencias.html", "Referências", " Referências "]
]
